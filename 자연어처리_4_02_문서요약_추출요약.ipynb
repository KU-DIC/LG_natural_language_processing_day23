{"cells":[{"cell_type":"markdown","metadata":{"id":"RDdaXxTuZ-oa"},"source":["## [LG 전자] 자연어 처리 # 4 : 문서요약 - (2)\n","\n","* Summarunner를 이용한 추출 요약\n","* 예상 난이도 ⭐️⭐️⭐️⭐️⭐️"]},{"cell_type":"markdown","metadata":{"id":"5S57xUrStZHq"},"source":["## 강의 복습\n","\n","강의자료 : 자연어처리 4, AGENDA 03 - 인공신경망 기반의 추출요약"]},{"cell_type":"markdown","metadata":{"id":"pH2OUSs8tdg9"},"source":["## 실습 요약"]},{"cell_type":"markdown","metadata":{"id":"oZtcUJkERwfC"},"source":["1. 본 실습에서는 SummaRunner를 활용하여 추출요약 모델을 구축합니다.\n","2. SummaRunner는 TextRank와 달리 학습을 통해 문서요약을 수행하는 지도학습 기반의 모델입니다.\n"]},{"cell_type":"markdown","metadata":{"id":"XvnpBm1PtVeV"},"source":["------"]},{"cell_type":"markdown","metadata":{"id":"xVvGtj7vYQ5v"},"source":["### STEP 0. 환경 구축하기\n","* 필요한 library들을 import 합니다"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YBWSfQGI-a8F"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install gensim==3.8.3"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1643076242178,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"WtIPKkNiaosp","outputId":"378a0a17-6bc1-4a22-b529-c0fc07977413"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python version:[3.7.0 (default, Oct  9 2018, 10:31:47) \n","[GCC 7.3.0]].\n","PyTorch version:[1.7.1].\n","device:[cuda:0].\n"]}],"source":["import sys\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","plt.rcParams['axes.unicode_minus'] = False\n","#%matplotlib inline #생성한 figure를 notebook에서 볼 수있게 해주는 코드\n","\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","#check torch version & device\n","print (\"Python version:[%s].\"%(sys.version))\n","print (\"PyTorch version:[%s].\"%(torch.__version__))\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print (\"device:[%s].\"%(device)) # device에 cuda:0가 프린트 된다면 GPU를 사용하는 상태입니다"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# konlpy, Mecab 형태소 분석기 설치 스크립트 실행\n","!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rUM2BsZMcCzC"},"outputs":[],"source":["# set random seed \n","\n","def set_seed(random_seed):\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)\n","    \n","random_seed = 42\n","set_seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"FACcqNcFcExO"},"source":["### STEP 1. 데이터 준비하기\n","금일 실습에서는 **AIHUB**에서 제공하는 **한글 뉴스기사 요약 데이터**를 활용합니다.\n","* 데이터셋 출처\n","  * https://aihub.or.kr/aidata/8054\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5-Vn2GBei2Vf"},"outputs":[],"source":["# github에서 데이터 불러오기\n","!git clone https://github.com/KU-DIC/LG_natural_language_processing_day23"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_prvLfHKcGqQ"},"outputs":[],"source":["# 데이터셋 읽기\n","with open('./LG_natural_language_processing_day23/data/sum_data.json','r',encoding='utf-8') as f:\n","  data = json.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":565,"status":"ok","timestamp":1643076254652,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"aeFWxr9bMOWh","outputId":"f8b89e58-cb99-407c-f0f4-de781632affd"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 243983/243983 [00:00<00:00, 2186948.63it/s]\n"]}],"source":["# 분석에 사용할 형태로 가공하기\n","label = [] # extractive\n","document = [] # text\n","\n","for cur_news in tqdm(data['documents']):\n","  # 리뷰 문장\n","  document.append(cur_news['text'])\n","  label.append(cur_news['extractive'])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BnaQBc06MmWn"},"outputs":[],"source":["# 데이터 프레임 형태로 변환하기\n","df = {\n","    \"label\" : label,\n","    \"document\" : document\n","}\n","df = pd.DataFrame(df)"]},{"cell_type":"markdown","metadata":{"id":"vW0B011dTyOo"},"source":["### STEP 2. 전처리 진행 (Preprocessing)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"WIySBkPocmLD"},"outputs":[],"source":["news_sentences = df['document'].to_list()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Q7j4w1z-tRuy"},"outputs":[],"source":["import re\n","def preprocess(text):\n","  text = re.sub('[-=+,#/\\?:^$~@*\\\"※~▲△&%ㆍ·!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', text)\n","  text = re.sub('[ㅠㅎㅋ]','', text)\n","  return text"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1643076268603,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"4dUBQnv6tg1f","outputId":"7b936da1-8f14-4aa8-d867-ba15c3601eb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12199/12199 [00:00<00:00, 204510.65it/s]\n","100%|██████████| 12199/12199 [00:00<00:00, 26746.34it/s]\n"]}],"source":["fixed_document = []\n","for cur_sentences in tqdm(news_sentences):\n","  fix_sent = []\n","  for sent in cur_sentences:\n","    fix_sent.extend(sent)\n","  fixed_document.append(fix_sent)\n","\n","normalize_document = []\n","for cur_sentences in tqdm(fixed_document):\n","  norm_sent = []\n","  for sent in cur_sentences:\n","    sentence = preprocess(sent['sentence'])\n","    norm_sent.append(sentence)\n","  normalize_document.append(norm_sent)\n","\n","df['normalize_document'] = normalize_document"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["label_sentence = []\n","for id, cur_doc in enumerate(df['normalize_document']):\n","    sent = []\n","    for idx in df['label'].iloc[id]:\n","        sent.append(cur_doc[idx])\n","    label_sentence.append(sent)\n","\n","df['label_sentence'] = label_sentence"]},{"cell_type":"markdown","metadata":{"id":"zjw-KFL0k5A1"},"source":["### STEP 3. 토큰화 진행 (Tokenization)\n","\n","* 문서 요약 실습에서는 단순 띄어쓰기 단위로 토큰화를 진행합니다\n","* 이유 : 문서요약 데이터는 하나의 데이터당 굉장히 많은 문장을 가지므로, 토큰화 과정에만 약 30분의 시간이 소요됨"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384917,"status":"ok","timestamp":1643076656483,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"FJ55fpYTvT0h","outputId":"76419604-3fa3-4f44-adf6-2f9a11945d23"},"outputs":[],"source":["# Okt(Open Korea Text)\n","# from konlpy.tag import Okt  \n","# okt = Okt() \n","\n","# tokenized_document = []\n","# for cur_doc in tqdm(normalize_document):\n","#   tokenized_sentence = []\n","#   for cur_sent in cur_doc:\n","#     sent = okt.morphs(cur_sent)\n","#     tokenized_sentence.append(sent)\n","#   tokenized_document.append(tokenized_sentence)\n","\n","# df['tokenized_document'] = tokenized_document"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12199/12199 [00:00<00:00, 50383.26it/s]\n"]}],"source":["tokenized_document = []\n","for cur_doc in tqdm(normalize_document):\n","  tokenized_sentence = []\n","  for cur_sent in cur_doc:\n","    sent = cur_sent.split(' ')\n","    tokenized_sentence.append(sent)\n","  tokenized_document.append(tokenized_sentence)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["df['tokenized_document'] = tokenized_document"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1643076657058,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"_KM7W6EaOLCi","outputId":"f5c86a13-4fd7-48e6-c3fe-9d8cb8f192d2"},"outputs":[{"data":{"text/plain":["(10972, 1217)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, test_df = train_test_split(df, test_size =0.1, random_state= 42)\n","\n","drop_list = [train_df.iloc[i].name for i in[845, 3035, 3936, 5246, 5417, 8988, 9710]]\n","train_df = train_df.drop(drop_list)\n","\n","drop_list = [test_df.iloc[i].name for i in [408,583,1000]]\n","test_df = test_df.drop(drop_list)\n","len(train_df) , len(test_df)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10972/10972 [00:00<00:00, 1117584.72it/s]\n"]}],"source":["aggregate_document =[]\n","for cur_doc in tqdm(train_df['tokenized_document']):\n","    _aggregate_document = [i for i in cur_doc]\n","    aggregate_document.append(_aggregate_document[0])\n","\n","train_df['aggregate_document'] = aggregate_document"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["labels = []\n","for idx, cur_doc in enumerate(train_df['normalize_document'].to_list()):\n","    label_idx = train_df['label'].iloc[idx]\n","    label = [0 for _ in range(len(cur_doc))]\n","\n","    for l_idx in label_idx :\n","        label[l_idx]=1\n","    labels.append(label)\n","train_df['labels'] = labels\n","\n","\n","labels = []\n","for idx, cur_doc in enumerate(test_df['normalize_document'].to_list()):\n","    label_idx = test_df['label'].iloc[idx]\n","    label = [0 for _ in range(len(cur_doc))]\n","\n","    for l_idx in label_idx :\n","        label[l_idx]=1\n","    labels.append(label)\n","test_df['labels'] = labels"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>document</th>\n","      <th>normalize_document</th>\n","      <th>label_sentence</th>\n","      <th>tokenized_document</th>\n","      <th>aggregate_document</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>185126</th>\n","      <td>[4, 5, 9]</td>\n","      <td>[[{'index': 0, 'sentence': '한꺼번에 뜬 수많은 금융권 채용 ...</td>\n","      <td>[한꺼번에 뜬 수많은 금융권 채용 공고를 마주한 취업준비생 입장에서 서류 접수는 빨...</td>\n","      <td>[특히 개인의 학력전공공인점수 등을 공개하지 않는 블라인드 채용이 자리 잡으면서 면...</td>\n","      <td>[[한꺼, 번, 에, 뜬, 수많은, 금융, 권, 채용, 공고, 를, 마주, 한, 취...</td>\n","      <td>[한꺼, 번, 에, 뜬, 수많은, 금융, 권, 채용, 공고, 를, 마주, 한, 취업...</td>\n","      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>134491</th>\n","      <td>[6, 12, 14]</td>\n","      <td>[[{'index': 0, 'sentence': '판교2밸리 적용 스마트시티 기술 ...</td>\n","      <td>[판교2밸리 적용 스마트시티 기술 조만간 선정 자료국토교통부 제공, 판교 제2테크노...</td>\n","      <td>[현재 검토되는 주요 스마트시티 기술 중 교통 분야는 자율주행버스를 비롯해 스마트 ...</td>\n","      <td>[[판교, 2, 밸리, 적용, 스마트, 시티, 기술, 조만간, 선정, 자료, 국토교...</td>\n","      <td>[판교, 2, 밸리, 적용, 스마트, 시티, 기술, 조만간, 선정, 자료, 국토교통...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>124873</th>\n","      <td>[6, 0, 2]</td>\n","      <td>[[{'index': 0, 'sentence': '설문대여성문화센터(소장 김정완)는...</td>\n","      <td>[설문대여성문화센터소장 김정완는 내달 2일부터 30일까지 2019 예술단체 발굴 지...</td>\n","      <td>[이번 전시에선 한국화 24점이 전시되며 강보라미 강명지 김혜정 작가 등 총 7명의...</td>\n","      <td>[[설문, 대, 여성, 문화센터, 소장, 김정, 완는, 내달, 2일, 부터, 30일...</td>\n","      <td>[설문, 대, 여성, 문화센터, 소장, 김정, 완는, 내달, 2일, 부터, 30일,...</td>\n","      <td>[1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>160900</th>\n","      <td>[0, 1, 2]</td>\n","      <td>[[{'index': 0, 'sentence': '경기도 화성시 ㈜착한건축자재백화점...</td>\n","      <td>[경기도 화성시 ㈜착한건축자재백화점의 심재옥 대표는 지진 발생 시 피해 최소화를 위...</td>\n","      <td>[경기도 화성시 ㈜착한건축자재백화점의 심재옥 대표는 지진 발생 시 피해 최소화를 위...</td>\n","      <td>[[경기도, 화성시, ㈜, 착한, 건축, 자재, 백화점, 의, 심재, 옥, 대표, ...</td>\n","      <td>[경기도, 화성시, ㈜, 착한, 건축, 자재, 백화점, 의, 심재, 옥, 대표, 는...</td>\n","      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>191075</th>\n","      <td>[2, 4, 10]</td>\n","      <td>[[{'index': 0, 'sentence': '23일 오후 서울 성북구 고려대학...</td>\n","      <td>[23일 오후 서울 성북구 고려대학교 서울캠퍼스 정경대 후문에 붙은 안녕들 하십니까...</td>\n","      <td>[23일 서울 성북구 고려대 서울캠퍼스 정경대 후문에 그래서 안녕들 하십니까라는 제...</td>\n","      <td>[[23일, 오후, 서울, 성북구, 고려대학교, 서울, 캠퍼스, 정경, 대, 후문,...</td>\n","      <td>[23일, 오후, 서울, 성북구, 고려대학교, 서울, 캠퍼스, 정경, 대, 후문, ...</td>\n","      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              label                                           document  \\\n","185126    [4, 5, 9]  [[{'index': 0, 'sentence': '한꺼번에 뜬 수많은 금융권 채용 ...   \n","134491  [6, 12, 14]  [[{'index': 0, 'sentence': '판교2밸리 적용 스마트시티 기술 ...   \n","124873    [6, 0, 2]  [[{'index': 0, 'sentence': '설문대여성문화센터(소장 김정완)는...   \n","160900    [0, 1, 2]  [[{'index': 0, 'sentence': '경기도 화성시 ㈜착한건축자재백화점...   \n","191075   [2, 4, 10]  [[{'index': 0, 'sentence': '23일 오후 서울 성북구 고려대학...   \n","\n","                                       normalize_document  \\\n","185126  [한꺼번에 뜬 수많은 금융권 채용 공고를 마주한 취업준비생 입장에서 서류 접수는 빨...   \n","134491  [판교2밸리 적용 스마트시티 기술 조만간 선정 자료국토교통부 제공, 판교 제2테크노...   \n","124873  [설문대여성문화센터소장 김정완는 내달 2일부터 30일까지 2019 예술단체 발굴 지...   \n","160900  [경기도 화성시 ㈜착한건축자재백화점의 심재옥 대표는 지진 발생 시 피해 최소화를 위...   \n","191075  [23일 오후 서울 성북구 고려대학교 서울캠퍼스 정경대 후문에 붙은 안녕들 하십니까...   \n","\n","                                           label_sentence  \\\n","185126  [특히 개인의 학력전공공인점수 등을 공개하지 않는 블라인드 채용이 자리 잡으면서 면...   \n","134491  [현재 검토되는 주요 스마트시티 기술 중 교통 분야는 자율주행버스를 비롯해 스마트 ...   \n","124873  [이번 전시에선 한국화 24점이 전시되며 강보라미 강명지 김혜정 작가 등 총 7명의...   \n","160900  [경기도 화성시 ㈜착한건축자재백화점의 심재옥 대표는 지진 발생 시 피해 최소화를 위...   \n","191075  [23일 서울 성북구 고려대 서울캠퍼스 정경대 후문에 그래서 안녕들 하십니까라는 제...   \n","\n","                                       tokenized_document  \\\n","185126  [[한꺼, 번, 에, 뜬, 수많은, 금융, 권, 채용, 공고, 를, 마주, 한, 취...   \n","134491  [[판교, 2, 밸리, 적용, 스마트, 시티, 기술, 조만간, 선정, 자료, 국토교...   \n","124873  [[설문, 대, 여성, 문화센터, 소장, 김정, 완는, 내달, 2일, 부터, 30일...   \n","160900  [[경기도, 화성시, ㈜, 착한, 건축, 자재, 백화점, 의, 심재, 옥, 대표, ...   \n","191075  [[23일, 오후, 서울, 성북구, 고려대학교, 서울, 캠퍼스, 정경, 대, 후문,...   \n","\n","                                       aggregate_document  \\\n","185126  [한꺼, 번, 에, 뜬, 수많은, 금융, 권, 채용, 공고, 를, 마주, 한, 취업...   \n","134491  [판교, 2, 밸리, 적용, 스마트, 시티, 기술, 조만간, 선정, 자료, 국토교통...   \n","124873  [설문, 대, 여성, 문화센터, 소장, 김정, 완는, 내달, 2일, 부터, 30일,...   \n","160900  [경기도, 화성시, ㈜, 착한, 건축, 자재, 백화점, 의, 심재, 옥, 대표, 는...   \n","191075  [23일, 오후, 서울, 성북구, 고려대학교, 서울, 캠퍼스, 정경, 대, 후문, ...   \n","\n","                                                   labels  \n","185126   [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n","134491  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n","124873               [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n","160900                  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n","191075                  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"NhZtdagGsTVe"},"source":["### STEP 4. 벡터화 진행 (Vectorization)\n","* 해당 실습에서는 별도의 벡터화를 수행한 후 모델링을 진행하지 않음\n","* 벡터화 과정을 모델 내부에서 수행하며, 이를 embedding이라 부름"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43614,"status":"ok","timestamp":1643076700664,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"QJjqfAyOrgKn","outputId":"d4cd374a-a74b-4569-e15d-0a450a02e2cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 12.6 s, sys: 665 ms, total: 13.3 s\n","Wall time: 11.5 s\n"]}],"source":["%%time\n","from gensim.models import FastText\n","\n","model = FastText(\n","    sentences = aggregate_document,\n","    size=100,\n","    window=5,\n","    min_count=1,\n","    workers=4)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Cb-lxhdkqq_g"},"outputs":[],"source":["# vocab"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4bUMcLxWW8a_"},"outputs":[],"source":["vocab = list(model.wv.vocab)\n","train_sentence = train_df['tokenized_document'].to_list()\n","test_sentence = test_df['tokenized_document'].to_list()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"p3Z9Zej2lJu3"},"outputs":[],"source":["word2index = {'<PAD>':0, '<UNK>':1}\n","\n","for v in vocab: # v는 vocab 객체 하나를 의미함\n","  if word2index.get(v) is None:\n","    word2index[v] = len(word2index) # 단어별 index 부여\n","\n","index2word = {}\n","for idx, vo in word2index.items():\n","  index2word[vo] = idx\n","\n","# 한줄로 구현하기\n","# index2word = {v:idx for idx, v in word2index.items()}"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RSCapb6Cy_rc"},"outputs":[],"source":["fasttext_vector = []\n","for key in word2index.keys():\n","  if key in '<PAD>' or '<UNK>': # 두가지 단어는 vocab에 속하지 않음 \n","    fasttext_vector.append(np.random.randn(100,)) # random한 값으로 초기화 하여 제공\n","  else:\n","    fasttext_vector.append(model.wv[key])\n","  \n","fasttext_matrix = np.vstack(fasttext_vector)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1643076782171,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"Xur5_ZgSoP8A","outputId":"268b4eaa-abf7-48b2-f0ef-fd70f2cfa944"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab 개수 :  48306\n","word matrix shape :  (48308, 100)\n"]}],"source":["print('vocab 개수 : ',len(vocab))\n","print('word matrix shape : ',fasttext_matrix.shape) # '<PAD>''<UNK>'를 추가해주었기 때문에 vocab보다 2개 많은 상태"]},{"cell_type":"markdown","metadata":{"id":"6v2UDIcOEoKb"},"source":["### STEP 5. 모델 구축하기 (Modeling)\n","* SummaRunner를 활용하여 문서 요약 모델 구축하기\n","* 딥러닝 모델을 위해서는 vocab, dataset, model을 구축해야함\n","* 그동안 배웠던 내용을 모두 함수로 묶어 진행함 (목적 : clean code를 위한 모듈화)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# vocab을 생성하는 Class\n","\n","class Feature:\n","    def __init__(self, word2id):\n","        self.word2id = word2id\n","        self.id2word = {idx: word for word, idx in word2id.items()}\n","        assert len(self.word2id) == len(self.id2word)\n","        self.PAD_IDX = 0\n","        self.UNK_IDX = 1\n","        self.PAD_TOKEN = \"<PAD>\"\n","        self.UNK_TOKEN = \"<UNK>\"\n","\n","    def __len__(self):\n","        return len(self.word2id)\n","\n","    def i2w(self, idx):\n","        return self.id2word[idx]\n","\n","    def w2i(self, w):\n","        if w in self.word2id:\n","            return self.word2id[w]\n","        else:\n","            return self.UNK_IDX\n","\n","    ###################\n","    # Create Features #\n","    ###################\n","    def make_features(\n","        self,\n","        docs,\n","        labels_list,\n","        summaries_list,\n","        sent_trunc=128,\n","        doc_trunc=100,\n","        split_token=\"\\n\",\n","    ):\n","\n","        # trunc document\n","        # 문서 내 doc_trunc 문장 개수까지 가져옴\n","        sents_list, targets, doc_lens, summaries = [], [], [], []\n","        for doc, labels, summary in zip(docs, labels_list, summaries_list):\n","            sents = doc #.split(split_token)\n","            labels = labels #.split(split_token)\n","            labels = [int(l) for l in labels]\n","            max_sent_num = min(doc_trunc, len(sents))\n","            sents = sents[:max_sent_num]\n","            labels = labels[:max_sent_num]\n","            oracle = [sent for sent, label in zip(sents, labels) if label == 1]\n","\n","            sents_list.extend(sents)\n","            targets.extend(labels)\n","            doc_lens.append(len(sents))\n","            summaries.append(summary)\n","\n","        # trunc or pad sent\n","        # 문장 내 sent_trunc 단어 개수까지 가져옴\n","        max_sent_len = 0\n","        batch_sents = []\n","        for sent in sents_list:\n","            words = sent.split()\n","            if len(words) > sent_trunc:\n","                words = words[:sent_trunc]\n","            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n","            batch_sents.append(words)\n","\n","        features = []\n","        for sent in batch_sents:\n","            feature = [self.PAD_IDX for _ in range(max_sent_len - len(sent))] + [\n","                self.w2i(w) for w in sent\n","            ]\n","            features.append(feature)\n","\n","        return features, targets, doc_lens, summaries\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# Dataset을 위한 Class\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class SummarRunnerDataset(Dataset):\n","    def __init__(self, examples):\n","        self.examples = examples\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, idx):\n","        doc = self.examples[idx][\"doc\"]\n","        labels = self.examples[idx][\"labels\"]\n","        summaries = self.examples[idx][\"summaries\"]\n","\n","        return doc, labels, summaries"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# model 정의\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","# from .encoder import SentenceEncoder, DocumentEncoder\n","# from .encoder import Encoder\n","\n","\n","# Device configuration\n","DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class SentenceEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        embed_dim: int = 100,\n","        hidden_dim: int = 128,\n","        num_layers: int = 1,\n","        bidirectional: bool = True,\n","        dropout_p: float = 0.3,\n","        pretrained_vectors: np.ndarray = None,\n","    ):\n","        super().__init__()\n","\n","        self.vocab_size = (vocab_size,)\n","        self.embed_dim = embed_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.num_directs = 1\n","        if bidirectional:\n","            self.num_directs = 2\n","\n","        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n","        if pretrained_vectors is not None:\n","            self.embed.weight.data.copy_(pretrained_vectors)\n","        else:\n","            nn.init.xavier_uniform_(self.embed.weight)\n","\n","        self.bilstm = nn.LSTM(\n","            self.embed_dim,\n","            self.hidden_dim,\n","            num_layers=self.num_layers,\n","            batch_first=True,\n","            bidirectional=self.bidirectional,\n","            # dropout=dropout,\n","        )\n","        # self.linear = nn.Linear(hidden_dim * 2, hidden_dim)\n","\n","    def avg_pool1d(self, sequences, seq_lens):\n","        out = []\n","        for idx, tensor in enumerate(sequences):\n","            tensor = tensor[: seq_lens[idx], :]\n","            tensor = torch.t(tensor).unsqueeze(0)\n","            out.append(F.avg_pool1d(tensor, tensor.size(2)))\n","\n","        out = torch.cat(out).squeeze(2)\n","        return out\n","\n","    def forward(self, docs):\n","        sent_lens = torch.sum(torch.sign(docs), dim=1).data\n","\n","        x = self.embed(docs)\n","        output, _ = self.bilstm(x)\n","        output = self.avg_pool1d(output, sent_lens)\n","        # output = self.linear(output)\n","\n","        return output\n","\n","\n","class DocumentEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        input_dim: int = 128,\n","        hidden_dim: int = 128,\n","        num_layers: int = 1,\n","        bidirectional: bool = True,\n","        dropout_p: float = 0.3,\n","    ):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.num_directs = 1\n","        if bidirectional:\n","            self.num_directs = 2\n","\n","        self.bilstm = nn.LSTM(\n","            input_dim,\n","            hidden_dim,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=bidirectional,\n","            # dropout=dropout,\n","        )\n","        # self.linear = nn.Linear(hidden_dim * 2, hidden_dim)\n","\n","    def pad_doc(self, sents, doc_lens):\n","        pad_dim = sents.size(1)\n","        max_doc_len = max(doc_lens)\n","        sent_input = []\n","        start = 0\n","        for doc_len in doc_lens:\n","            stop = start + doc_len\n","            valid = sents[start:stop]\n","            start = stop\n","            if doc_len == max_doc_len:\n","                sent_input.append(valid.unsqueeze(0))\n","            else:\n","                pad = Variable(torch.zeros(max_doc_len - doc_len, pad_dim)).to(DEVICE)\n","                sent_input.append(torch.cat([valid, pad]).unsqueeze(0))\n","\n","        sent_input = torch.cat(sent_input, dim=0)\n","        return sent_input\n","\n","    def avg_pool1d(self, sequences, seq_lens):\n","        out = []\n","        for idx, tensor in enumerate(sequences):\n","            tensor = tensor[: seq_lens[idx], :]\n","            tensor = torch.t(tensor).unsqueeze(0)\n","            out.append(F.avg_pool1d(tensor, tensor.size(2)))\n","\n","        out = torch.cat(out).squeeze(2)\n","        return out\n","\n","    def forward(self, sents, doc_lens):\n","        # make sent features(pad with zeros)\n","        x = self.pad_doc(sents, doc_lens)\n","        output, hidden = self.bilstm(x)\n","        # output = self.linear(output)\n","        return output\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        embed_dim: int = 100,\n","        hidden_dim: int = 128,\n","        num_layers: int = 1,\n","        bidirectional: bool = True,\n","        dropout_p: float = 0.3,\n","        pretrained_vectors: np.ndarray = None,\n","    ):\n","        super().__init__()\n","\n","        self.sent_encoder = SentenceEncoder(\n","            vocab_size,\n","            embed_dim,\n","            hidden_dim,\n","            num_layers,\n","            bidirectional=True,\n","            dropout_p=dropout_p,\n","            pretrained_vectors=pretrained_vectors,\n","        )\n","\n","        self.doc_encoder = DocumentEncoder(\n","            2 * hidden_dim,\n","            hidden_dim,\n","            num_layers,\n","            bidirectional=True,\n","            dropout_p=dropout_p,\n","        )\n","\n","    def forward(self, docs, doc_lens):\n","        encoded_sents = self.sent_encoder(docs)\n","        encoded_docs = self.doc_encoder(encoded_sents, doc_lens)\n","        return encoded_docs\n","\n","\n","class SummaRunner(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        num_class: int = 1,\n","        embed_dim: int = 100,\n","        hidden_dim: int = 128,\n","        pos_dim: int = 50,\n","        pos_num: int = 100,\n","        seg_num: int = 10,\n","        num_layers: int = 1,\n","        bidirectional: bool = True,\n","        dropout_p: float = 0.3,\n","        maxlen: int = 50,\n","        pretrained_vectors: np.ndarray = None,\n","    ):\n","        super(SummaRunner, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.abs_pos_embed = nn.Embedding(pos_num, pos_dim)  # absolute postion\n","        self.rel_pos_embed = nn.Embedding(seg_num, pos_dim)  # relative position\n","\n","        self.encoder = Encoder(\n","            vocab_size, embed_dim, hidden_dim, num_layers, bidirectional, dropout_p\n","        )\n","\n","        self.fc = nn.Linear(2 * hidden_dim, 2 * hidden_dim)\n","\n","        # Parameters of Classification Layer\n","        # P(y_j = 1|h_j, s_j, d), Eq.6 in SummaRuNNer paper\n","        self.content = nn.Linear(2 * hidden_dim, 1, bias=False)\n","        self.salience = nn.Bilinear(2 * hidden_dim, 2 * hidden_dim, 1, bias=False)\n","        self.novelty = nn.Bilinear(2 * hidden_dim, 2 * hidden_dim, 1, bias=False)\n","        self.abs_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.rel_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n","\n","    def avg_pool1d(self, sequences, seq_lens):\n","        out = []\n","        for idx, tensor in enumerate(sequences):\n","            tensor = tensor[: seq_lens[idx], :]\n","            tensor = torch.t(tensor).unsqueeze(0)\n","            out.append(F.avg_pool1d(tensor, tensor.size(2)))\n","\n","        out = torch.cat(out).squeeze(2)\n","        return out\n","\n","    def forward(self, docs, doc_lens):\n","        sent_out = self.encoder(docs, doc_lens)\n","        docs = self.avg_pool1d(sent_out, doc_lens)\n","\n","        probs = []\n","        for index, doc_len in enumerate(doc_lens):\n","            valid_hidden = sent_out[index, :doc_len, :]\n","            doc = torch.tanh(self.fc(docs[index])).unsqueeze(0)\n","            s = Variable(torch.zeros(1, 2 * self.hidden_dim)).to(DEVICE)\n","            for position, h in enumerate(valid_hidden):\n","                h = h.view(1, -1)\n","                # get position embeddings\n","                abs_index = Variable(torch.LongTensor([[position]])).to(DEVICE)\n","                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n","\n","                rel_index = int(round((position + 1) * 9.0 / doc_len))\n","                rel_index = Variable(torch.LongTensor([[rel_index]])).to(DEVICE)\n","                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n","\n","                # classification layer\n","                content = self.content(h)\n","                salience = self.salience(h, doc)\n","                novelty = -1 * self.novelty(h, torch.tanh(s))\n","                abs_p = self.abs_pos(abs_features)\n","                rel_p = self.rel_pos(rel_features)\n","                # P(y_j = 1|h_j, s_j, d) Eq.6 in SummaRuNNer paper\n","                prob = torch.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n","                s = s + torch.mm(prob, h)\n","                probs.append(prob)\n","\n","        return torch.cat(probs).squeeze()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# make example\n","# 모델이 원하는 스타일의 데이터로 바꾸어주는 부분\n","\n","train_examples = []\n","\n","for cur_example in zip(train_df['normalize_document'],train_df['labels'],train_df['label_sentence']):\n","    example = {\n","        'doc': cur_example[0],\n","        'labels': cur_example[1],\n","        'summaries': cur_example[2]\n","    }\n","    train_examples.append(example)\n","\n","test_examples = []\n","\n","for cur_example in zip(test_df['normalize_document'],test_df['labels'],test_df['label_sentence']):\n","    example = {\n","        'doc': cur_example[0],\n","        'labels': cur_example[1],\n","        'summaries': cur_example[2]\n","    }\n","    test_examples.append(example)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["1217"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["len(test_examples)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def accuracy(logits, labels):\n","    preds = torch.round(logits)\n","    corrects = (preds == labels).sum().float()\n","    acc = corrects / labels.numel()\n","    return acc"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# train\n","\n","EPOCH = 5\n","BATCH_SIZE = 30\n","LR = 0.001"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def collate_fn(batch, feature, doc_trunc=100):\n","    docs = [entry[0] for entry in batch]\n","    labels_list = [entry[1] for entry in batch]\n","    summaries = [entry[2] for entry in batch]\n","\n","    features, targets, doc_lens, summaries = feature.make_features(\n","        docs, labels_list, summaries, doc_trunc=doc_trunc\n","    )\n","    \n","    features = torch.LongTensor(features)\n","    targets = torch.FloatTensor(targets)\n","    return features, targets, doc_lens, summaries"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from functools import partial\n","\n","feature = Feature(word2index)\n","\n","train_dataset = SummarRunnerDataset(train_examples)\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    collate_fn=partial(collate_fn, feature=feature),\n","    )"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["model = SummaRunner(\n","    vocab_size=len(word2index),\n","    num_class=1,\n","    embed_dim=100,\n","    hidden_dim=128,\n","    pos_dim=50,\n","    pos_num=100,\n","    seg_num=10,\n","    num_layers=1,\n","    bidirectional=True,\n","    dropout_p=0.3,\n","    maxlen=100,\n","    pretrained_vectors=fasttext_matrix\n",")\n","\n","model = model.to(device)\n","    \n","loss_function = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch ID: 0, Loss: 0.7848403453826904, Acc: 0.5013550519943237\n","Batch ID: 100, Loss: 0.41332948207855225, Acc: 0.8138957619667053\n","Batch ID: 200, Loss: 0.3994556963443756, Acc: 0.8362282514572144\n","Batch ID: 300, Loss: 0.4436092674732208, Acc: 0.8115501403808594\n","Batch ID: 0, Loss: 0.4189411997795105, Acc: 0.8075881004333496\n","Batch ID: 100, Loss: 0.4233170449733734, Acc: 0.8163771629333496\n","Batch ID: 200, Loss: 0.3919476568698883, Acc: 0.8312655091285706\n","Batch ID: 300, Loss: 0.43431755900382996, Acc: 0.8085106611251831\n","Batch ID: 0, Loss: 0.4080554246902466, Acc: 0.8157181739807129\n","Batch ID: 100, Loss: 0.42411670088768005, Acc: 0.8138957619667053\n","Batch ID: 200, Loss: 0.3765488266944885, Acc: 0.8387096524238586\n","Batch ID: 300, Loss: 0.4104790687561035, Acc: 0.8145896792411804\n","Batch ID: 0, Loss: 0.37991562485694885, Acc: 0.8130081295967102\n","Batch ID: 100, Loss: 0.41270336508750916, Acc: 0.826302707195282\n","Batch ID: 200, Loss: 0.359308660030365, Acc: 0.8411910533905029\n","Batch ID: 300, Loss: 0.38651812076568604, Acc: 0.8449848294258118\n","Batch ID: 0, Loss: 0.3332982659339905, Acc: 0.8211382031440735\n","Batch ID: 100, Loss: 0.41106441617012024, Acc: 0.826302707195282\n","Batch ID: 200, Loss: 0.3545362651348114, Acc: 0.8362282514572144\n","Batch ID: 300, Loss: 0.3559034764766693, Acc: 0.848024308681488\n"]}],"source":["from torch.nn.utils import clip_grad_norm_\n","\n","model.train()\n","for epoch in tqdm(range(EPOCH)):\n","    batch_loss = []\n","    for step, batch in enumerate(train_loader):\n","        features, targets, doc_lens, _ = batch\n","        \n","        features = features.to(device)\n","        targets = targets.to(device)\n","        \n","        model.zero_grad()\n","        probs = model(features, doc_lens)\n","        \n","        loss = loss_function(probs, targets)\n","        batch_loss.append(loss.item())\n","        loss.backward()\n","        \n","        clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        if step % 100 == 0:\n","            train_acc = accuracy(probs, targets)\n","            print(' ')\n","            print(f'Step: {step}, Loss: {loss.item()}, Acc: {train_acc}')"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# test\n","test_dataset = SummarRunnerDataset(test_examples)\n","\n","test_loader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    collate_fn=partial(collate_fn, feature=feature),\n","    )"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["model.eval()\n","\n","model_prediction = []\n","test_label = []\n","with torch.no_grad():\n","    for step, batch in enumerate(test_loader):\n","        features, targets, doc_lens, _ = batch\n","\n","        features = features.to(device)\n","        targets = targets.to(device)\n","        \n","        probs = model(features, doc_lens)\n","        start = 0\n","        for doc_id, doc_len in enumerate(doc_lens):\n","            # print(doc_len)\n","            stop = start + doc_len\n","            prob = probs[start:stop]\n","            # print(prob)\n","            topk = min(3, doc_len)\n","            topk_indices = prob.topk(topk)[1].cpu().data.numpy()\n","            topk_indices.sort()\n","\n","            model_prediction.append(topk_indices)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/plain":["1217"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["len(model_prediction)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["all_pred = []\n","for idx, cur_doc in enumerate(test_df['normalize_document']):\n","    pred_idx = model_prediction[idx]\n","    pred_doc = []\n","    for cur_idx in pred_idx:\n","        pred_doc.append(cur_doc[cur_idx])\n","    all_pred.append(pred_doc)"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["all_label = test_df['label_sentence'].to_list()"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"data":{"text/plain":["(1217, 1217)"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["len(all_pred), len(all_label)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["'''\n","rouge score 계산을 위한 코드이며, \n","해당 실습에서는 score 계산에 필요한 전체적인 흐름을 따라갈 목적으로서 해당 코드를 사용합니다.\n","즉, rouge score의 계산원리를 모두 익히지 않아도 됩니다.\n","'''\n","\n","import os\n","import re\n","import platform\n","import itertools\n","import collections\n","import pkg_resources  # pip install py-rouge\n","from io import open\n","\n","if platform.system() == \"Windows\":\n","    try:\n","        from eunjeon import Mecab\n","    except:\n","        print(\"please install eunjeon module\")\n","else:  # Ubuntu일 경우\n","    from konlpy.tag import Mecab\n","\n","\n","class Rouge:\n","    DEFAULT_METRICS = {\"rouge-n\"}\n","    DEFAULT_N = 1\n","    STATS = [\"f\", \"p\", \"r\"]\n","    AVAILABLE_METRICS = {\"rouge-n\", \"rouge-l\", \"rouge-w\"}\n","    AVAILABLE_LENGTH_LIMIT_TYPES = {\"words\", \"bytes\"}\n","    REMOVE_CHAR_PATTERN = re.compile(\"[^A-Za-z0-9가-힣]\")\n","\n","    def __init__(\n","        self,\n","        metrics=None,\n","        max_n=None,\n","        limit_length=True,\n","        length_limit=1000,\n","        length_limit_type=\"words\",\n","        apply_avg=True,\n","        apply_best=False,\n","        use_tokenizer=True,\n","        alpha=0.5,\n","        weight_factor=1.0,\n","    ):\n","        self.metrics = metrics[:] if metrics is not None else Rouge.DEFAULT_METRICS\n","        for m in self.metrics:\n","            if m not in Rouge.AVAILABLE_METRICS:\n","                raise ValueError(\"Unknown metric '{}'\".format(m))\n","\n","        self.max_n = max_n if \"rouge-n\" in self.metrics else None\n","        # Add all rouge-n metrics\n","        if self.max_n is not None:\n","            index_rouge_n = self.metrics.index(\"rouge-n\")\n","            del self.metrics[index_rouge_n]\n","            self.metrics += [\"rouge-{}\".format(n) for n in range(1, self.max_n + 1)]\n","        self.metrics = set(self.metrics)\n","\n","        self.limit_length = limit_length\n","        if self.limit_length:\n","            if length_limit_type not in Rouge.AVAILABLE_LENGTH_LIMIT_TYPES:\n","                raise ValueError(\"Unknown length_limit_type '{}'\".format(length_limit_type))\n","\n","        self.length_limit = length_limit\n","        if self.length_limit == 0:\n","            self.limit_length = False\n","        self.length_limit_type = length_limit_type\n","\n","        self.use_tokenizer = use_tokenizer\n","        if use_tokenizer:\n","            self.tokenizer = Mecab()\n","\n","        self.apply_avg = apply_avg\n","        self.apply_best = apply_best\n","        self.alpha = alpha\n","        self.weight_factor = weight_factor\n","        if self.weight_factor <= 0:\n","            raise ValueError(\"ROUGE-W weight factor must greater than 0.\")\n","\n","    def tokenize_text(self, text):\n","        return self.tokenizer.morphs(text)\n","\n","    @staticmethod\n","    def split_into_sentences(text):\n","        return text.split(\"\\n\")\n","\n","    @staticmethod\n","    def _get_ngrams(n, text):\n","        ngram_set = collections.defaultdict(int)\n","        max_index_ngram_start = len(text) - n\n","        for i in range(max_index_ngram_start + 1):\n","            ngram_set[tuple(text[i : i + n])] += 1\n","        return ngram_set\n","\n","    @staticmethod\n","    def _split_into_words(sentences):\n","        return list(itertools.chain(*[_.split() for _ in sentences]))\n","\n","    @staticmethod\n","    def _get_word_ngrams_and_length(n, sentences):\n","        assert len(sentences) > 0\n","        assert n > 0\n","\n","        tokens = Rouge._split_into_words(sentences)\n","        return Rouge._get_ngrams(n, tokens), tokens, len(tokens) - (n - 1)\n","\n","    @staticmethod\n","    def _get_unigrams(sentences):\n","        assert len(sentences) > 0\n","\n","        tokens = Rouge._split_into_words(sentences)\n","        unigram_set = collections.defaultdict(int)\n","        for token in tokens:\n","            unigram_set[token] += 1\n","        return unigram_set, len(tokens)\n","\n","    @staticmethod\n","    def _compute_p_r_f_score(\n","        evaluated_count,\n","        reference_count,\n","        overlapping_count,\n","        alpha=0.5,\n","        weight_factor=1.0,\n","    ):\n","        precision = 0.0 if evaluated_count == 0 else overlapping_count / float(evaluated_count)\n","        if weight_factor != 1.0:\n","            precision = precision ** (1.0 / weight_factor)\n","        recall = 0.0 if reference_count == 0 else overlapping_count / float(reference_count)\n","        if weight_factor != 1.0:\n","            recall = recall ** (1.0 / weight_factor)\n","        f1_score = Rouge._compute_f_score(precision, recall, alpha)\n","        return {\"f\": f1_score, \"p\": precision, \"r\": recall}\n","\n","    @staticmethod\n","    def _compute_f_score(precision, recall, alpha=0.5):\n","        return (\n","            0.0\n","            if (recall == 0.0 or precision == 0.0)\n","            else precision * recall / ((1 - alpha) * precision + alpha * recall)\n","        )\n","\n","    @staticmethod\n","    def _compute_ngrams(evaluated_sentences, reference_sentences, n):\n","        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n","            raise ValueError(\"Collections must contain at least 1 sentence.\")\n","\n","        evaluated_ngrams, _, evaluated_count = Rouge._get_word_ngrams_and_length(\n","            n, evaluated_sentences\n","        )\n","        reference_ngrams, _, reference_count = Rouge._get_word_ngrams_and_length(\n","            n, reference_sentences\n","        )\n","\n","        # Gets the overlapping ngrams between evaluated and reference\n","        overlapping_ngrams = set(evaluated_ngrams.keys()).intersection(set(reference_ngrams.keys()))\n","        overlapping_count = 0\n","        for ngram in overlapping_ngrams:\n","            overlapping_count += min(evaluated_ngrams[ngram], reference_ngrams[ngram])\n","\n","        return evaluated_count, reference_count, overlapping_count\n","\n","    @staticmethod\n","    def _compute_ngrams_lcs(evaluated_sentences, reference_sentences, weight_factor=1.0):\n","        def _lcs(x, y):\n","            m = len(x)\n","            n = len(y)\n","            vals = collections.defaultdict(int)\n","            dirs = collections.defaultdict(int)\n","\n","            for i in range(1, m + 1):\n","                for j in range(1, n + 1):\n","                    if x[i - 1] == y[j - 1]:\n","                        vals[i, j] = vals[i - 1, j - 1] + 1\n","                        dirs[i, j] = \"|\"\n","                    elif vals[i - 1, j] >= vals[i, j - 1]:\n","                        vals[i, j] = vals[i - 1, j]\n","                        dirs[i, j] = \"^\"\n","                    else:\n","                        vals[i, j] = vals[i, j - 1]\n","                        dirs[i, j] = \"<\"\n","\n","            return vals, dirs\n","\n","        def _wlcs(x, y, weight_factor):\n","            m = len(x)\n","            n = len(y)\n","            vals = collections.defaultdict(float)\n","            dirs = collections.defaultdict(int)\n","            lengths = collections.defaultdict(int)\n","\n","            for i in range(1, m + 1):\n","                for j in range(1, n + 1):\n","                    if x[i - 1] == y[j - 1]:\n","                        length_tmp = lengths[i - 1, j - 1]\n","                        vals[i, j] = (\n","                            vals[i - 1, j - 1]\n","                            + (length_tmp + 1) ** weight_factor\n","                            - length_tmp ** weight_factor\n","                        )\n","                        dirs[i, j] = \"|\"\n","                        lengths[i, j] = length_tmp + 1\n","                    elif vals[i - 1, j] >= vals[i, j - 1]:\n","                        vals[i, j] = vals[i - 1, j]\n","                        dirs[i, j] = \"^\"\n","                        lengths[i, j] = 0\n","                    else:\n","                        vals[i, j] = vals[i, j - 1]\n","                        dirs[i, j] = \"<\"\n","                        lengths[i, j] = 0\n","\n","            return vals, dirs\n","\n","        def _mark_lcs(mask, dirs, m, n):\n","            while m != 0 and n != 0:\n","                if dirs[m, n] == \"|\":\n","                    m -= 1\n","                    n -= 1\n","                    mask[m] = 1\n","                elif dirs[m, n] == \"^\":\n","                    m -= 1\n","                elif dirs[m, n] == \"<\":\n","                    n -= 1\n","                else:\n","                    raise UnboundLocalError(\"Illegal move\")\n","\n","            return mask\n","\n","        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n","            raise ValueError(\"Collections must contain at least 1 sentence.\")\n","\n","        evaluated_unigrams_dict, evaluated_count = Rouge._get_unigrams(evaluated_sentences)\n","        reference_unigrams_dict, reference_count = Rouge._get_unigrams(reference_sentences)\n","\n","        # Has to use weight factor for WLCS\n","        use_WLCS = weight_factor != 1.0\n","        if use_WLCS:\n","            evaluated_count = evaluated_count ** weight_factor\n","            reference_count = 0\n","\n","        overlapping_count = 0.0\n","        for reference_sentence in reference_sentences:\n","            reference_sentence_tokens = reference_sentence.split()\n","            if use_WLCS:\n","                reference_count += len(reference_sentence_tokens) ** weight_factor\n","            hit_mask = [0 for _ in range(len(reference_sentence_tokens))]\n","\n","            for evaluated_sentence in evaluated_sentences:\n","                evaluated_sentence_tokens = evaluated_sentence.split()\n","\n","                if use_WLCS:\n","                    _, lcs_dirs = _wlcs(\n","                        reference_sentence_tokens,\n","                        evaluated_sentence_tokens,\n","                        weight_factor,\n","                    )\n","                else:\n","                    _, lcs_dirs = _lcs(reference_sentence_tokens, evaluated_sentence_tokens)\n","                _mark_lcs(\n","                    hit_mask,\n","                    lcs_dirs,\n","                    len(reference_sentence_tokens),\n","                    len(evaluated_sentence_tokens),\n","                )\n","\n","            overlapping_count_length = 0\n","            for ref_token_id, val in enumerate(hit_mask):\n","                if val == 1:\n","                    token = reference_sentence_tokens[ref_token_id]\n","                    if evaluated_unigrams_dict[token] > 0 and reference_unigrams_dict[token] > 0:\n","                        evaluated_unigrams_dict[token] -= 1\n","                        reference_unigrams_dict[ref_token_id] -= 1\n","\n","                        if use_WLCS:\n","                            overlapping_count_length += 1\n","                            if (\n","                                ref_token_id + 1 < len(hit_mask) and hit_mask[ref_token_id + 1] == 0\n","                            ) or ref_token_id + 1 == len(hit_mask):\n","                                overlapping_count += overlapping_count_length ** weight_factor\n","                                overlapping_count_length = 0\n","                        else:\n","                            overlapping_count += 1\n","\n","        if use_WLCS:\n","            reference_count = reference_count ** weight_factor\n","\n","        return evaluated_count, reference_count, overlapping_count\n","\n","    def get_scores(self, hypothesis, references):\n","        if isinstance(hypothesis, str):\n","            hypothesis, references = [hypothesis], [references]\n","\n","        if type(hypothesis) != type(references):\n","            raise ValueError(\"'hyps' and 'refs' are not of the same type\")\n","\n","        if len(hypothesis) != len(references):\n","            raise ValueError(\"'hyps' and 'refs' do not have the same length\")\n","        scores = {}\n","        has_rouge_n_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].isdigit()]) > 0\n","        )\n","        if has_rouge_n_metric:\n","            scores.update(self._get_scores_rouge_n(hypothesis, references))\n","            # scores = {**scores, **self._get_scores_rouge_n(hypothesis, references)}\n","\n","        has_rouge_l_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].lower() == \"l\"]) > 0\n","        )\n","        if has_rouge_l_metric:\n","            scores.update(self._get_scores_rouge_l_or_w(hypothesis, references, False))\n","            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, False)}\n","\n","        has_rouge_w_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].lower() == \"w\"]) > 0\n","        )\n","        if has_rouge_w_metric:\n","            scores.update(self._get_scores_rouge_l_or_w(hypothesis, references, True))\n","            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, True)}\n","\n","        return scores\n","\n","    def _get_scores_rouge_n(self, all_hypothesis, all_references):\n","        metrics = [metric for metric in self.metrics if metric.split(\"-\")[-1].isdigit()]\n","\n","        if self.apply_avg or self.apply_best:\n","            scores = {metric: {stat: 0.0 for stat in Rouge.STATS} for metric in metrics}\n","        else:\n","            scores = {\n","                metric: [{stat: [] for stat in Rouge.STATS} for _ in range(len(all_hypothesis))]\n","                for metric in metrics\n","            }\n","\n","        for sample_id, (hypothesis, references) in enumerate(zip(all_hypothesis, all_references)):\n","            assert isinstance(hypothesis, str)\n","            has_multiple_references = False\n","            if isinstance(references, list):\n","                has_multiple_references = len(references) > 1\n","                if not has_multiple_references:\n","                    references = references[0]\n","\n","            # Prepare hypothesis and reference(s)\n","            hypothesis = self._preprocess_summary_as_a_whole(hypothesis)\n","            references = (\n","                [self._preprocess_summary_as_a_whole(reference) for reference in references]\n","                if has_multiple_references\n","                else [self._preprocess_summary_as_a_whole(references)]\n","            )\n","\n","            # Compute scores\n","            for metric in metrics:\n","                suffix = metric.split(\"-\")[-1]\n","                n = int(suffix)\n","\n","                # Aggregate\n","                if self.apply_avg:\n","                    # average model\n","                    total_hypothesis_ngrams_count = 0\n","                    total_reference_ngrams_count = 0\n","                    total_ngrams_overlapping_count = 0\n","\n","                    for reference in references:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                        total_hypothesis_ngrams_count += hypothesis_count\n","                        total_reference_ngrams_count += reference_count\n","                        total_ngrams_overlapping_count += overlapping_ngrams\n","\n","                    score = Rouge._compute_p_r_f_score(\n","                        total_hypothesis_ngrams_count,\n","                        total_reference_ngrams_count,\n","                        total_ngrams_overlapping_count,\n","                        self.alpha,\n","                    )\n","\n","                    for stat in Rouge.STATS:\n","                        scores[metric][stat] += score[stat]\n","                else:\n","                    # Best model\n","                    if self.apply_best:\n","                        best_current_score = None\n","                        for reference in references:\n","                            (\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                            score = Rouge._compute_p_r_f_score(\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                                self.alpha,\n","                            )\n","                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n","                                best_current_score = score\n","\n","                        for stat in Rouge.STATS:\n","                            scores[metric][stat] += best_current_score[stat]\n","                    # Keep all\n","                    else:\n","                        for reference in references:\n","                            (\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                            score = Rouge._compute_p_r_f_score(\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                                self.alpha,\n","                            )\n","                            for stat in Rouge.STATS:\n","                                scores[metric][sample_id][stat].append(score[stat])\n","\n","        # Compute final score with the average or the the max\n","        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n","            for metric in metrics:\n","                for stat in Rouge.STATS:\n","                    scores[metric][stat] /= len(all_hypothesis)\n","\n","        return scores\n","\n","    def _get_scores_rouge_l_or_w(self, all_hypothesis, all_references, use_w=False):\n","        metric = \"rouge-w\" if use_w else \"rouge-l\"\n","        if self.apply_avg or self.apply_best:\n","            scores = {metric: {stat: 0.0 for stat in Rouge.STATS}}\n","        else:\n","            scores = {\n","                metric: [{stat: [] for stat in Rouge.STATS} for _ in range(len(all_hypothesis))]\n","            }\n","\n","        for sample_id, (hypothesis_sentences, references_sentences) in enumerate(\n","            zip(all_hypothesis, all_references)\n","        ):\n","            assert isinstance(hypothesis_sentences, str)\n","            has_multiple_references = False\n","            if isinstance(references_sentences, list):\n","                has_multiple_references = len(references_sentences) > 1\n","                if not has_multiple_references:\n","                    references_sentences = references_sentences[0]\n","\n","            # Prepare hypothesis and reference(s)\n","            hypothesis_sentences = self._preprocess_summary_per_sentence(hypothesis_sentences)\n","            references_sentences = (\n","                [\n","                    self._preprocess_summary_per_sentence(reference)\n","                    for reference in references_sentences\n","                ]\n","                if has_multiple_references\n","                else [self._preprocess_summary_per_sentence(references_sentences)]\n","            )\n","\n","            # Compute scores\n","            # Aggregate\n","            if self.apply_avg:\n","                # average model\n","                total_hypothesis_ngrams_count = 0\n","                total_reference_ngrams_count = 0\n","                total_ngrams_overlapping_count = 0\n","\n","                for reference_sentences in references_sentences:\n","                    (\n","                        hypothesis_count,\n","                        reference_count,\n","                        overlapping_ngrams,\n","                    ) = Rouge._compute_ngrams_lcs(\n","                        hypothesis_sentences,\n","                        reference_sentences,\n","                        self.weight_factor if use_w else 1.0,\n","                    )\n","                    total_hypothesis_ngrams_count += hypothesis_count\n","                    total_reference_ngrams_count += reference_count\n","                    total_ngrams_overlapping_count += overlapping_ngrams\n","\n","                score = Rouge._compute_p_r_f_score(\n","                    total_hypothesis_ngrams_count,\n","                    total_reference_ngrams_count,\n","                    total_ngrams_overlapping_count,\n","                    self.alpha,\n","                    self.weight_factor if use_w else 1.0,\n","                )\n","                for stat in Rouge.STATS:\n","                    scores[metric][stat] += score[stat]\n","            else:\n","                # Best model\n","                if self.apply_best:\n","                    best_current_score = None\n","                    best_current_score_wlcs = None\n","                    for reference_sentences in references_sentences:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams_lcs(\n","                            hypothesis_sentences,\n","                            reference_sentences,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","                        score = Rouge._compute_p_r_f_score(\n","                            total_hypothesis_ngrams_count,\n","                            total_reference_ngrams_count,\n","                            total_ngrams_overlapping_count,\n","                            self.alpha,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","\n","                        if use_w:\n","                            reference_count_for_score = reference_count ** (\n","                                1.0 / self.weight_factor\n","                            )\n","                            overlapping_ngrams_for_score = overlapping_ngrams\n","                            score_wlcs = (\n","                                overlapping_ngrams_for_score / reference_count_for_score\n","                            ) ** (1.0 / self.weight_factor)\n","\n","                            if (\n","                                best_current_score_wlcs is None\n","                                or score_wlcs > best_current_score_wlcs\n","                            ):\n","                                best_current_score = score\n","                                best_current_score_wlcs = score_wlcs\n","                        else:\n","                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n","                                best_current_score = score\n","\n","                    for stat in Rouge.STATS:\n","                        scores[metric][stat] += best_current_score[stat]\n","                # Keep all\n","                else:\n","                    for reference_sentences in references_sentences:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams_lcs(\n","                            hypothesis_sentences,\n","                            reference_sentences,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","                        score = Rouge._compute_p_r_f_score(\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                            self.alpha,\n","                            self.weight_factor,\n","                        )\n","\n","                        for stat in Rouge.STATS:\n","                            scores[metric][sample_id][stat].append(score[stat])\n","\n","        # Compute final score with the average or the the max\n","        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n","            for stat in Rouge.STATS:\n","                scores[metric][stat] /= len(all_hypothesis)\n","\n","        return scores\n","\n","    def _preprocess_summary_as_a_whole(self, summary):\n","        sentences = Rouge.split_into_sentences(summary)\n","\n","        # Truncate\n","        if self.limit_length:\n","            # By words\n","            if self.length_limit_type == \"words\":\n","                summary = \" \".join(sentences)\n","                all_tokens = summary.split()  # Counting as in the perls script\n","                summary = \" \".join(all_tokens[: self.length_limit])\n","\n","            # By bytes\n","            elif self.length_limit_type == \"bytes\":\n","                summary = \"\"\n","                current_len = 0\n","                for sentence in sentences:\n","                    sentence = sentence.strip()\n","                    sentence_len = len(sentence)\n","\n","                    if current_len + sentence_len < self.length_limit:\n","                        if current_len != 0:\n","                            summary += \" \"\n","                        summary += sentence\n","                        current_len += sentence_len\n","                    else:\n","                        if current_len > 0:\n","                            summary += \" \"\n","                        summary += sentence[: self.length_limit - current_len]\n","                        break\n","        else:\n","            summary = \" \".join(sentences)\n","\n","        summary = Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary.lower()).strip()\n","\n","        tokens = self.tokenize_text(Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary))\n","        preprocessed_summary = [\" \".join(tokens)]\n","\n","        return preprocessed_summary\n","\n","    def _preprocess_summary_per_sentence(self, summary):\n","        sentences = Rouge.split_into_sentences(summary)\n","\n","        # Truncate\n","        if self.limit_length:\n","            final_sentences = []\n","            current_len = 0\n","            # By words\n","            if self.length_limit_type == \"words\":\n","                for sentence in sentences:\n","                    tokens = sentence.strip().split()\n","                    tokens_len = len(tokens)\n","                    if current_len + tokens_len < self.length_limit:\n","                        sentence = \" \".join(tokens)\n","                        final_sentences.append(sentence)\n","                        current_len += tokens_len\n","                    else:\n","                        sentence = \" \".join(tokens[: self.length_limit - current_len])\n","                        final_sentences.append(sentence)\n","                        break\n","            # By bytes\n","            elif self.length_limit_type == \"bytes\":\n","                for sentence in sentences:\n","                    sentence = sentence.strip()\n","                    sentence_len = len(sentence)\n","                    if current_len + sentence_len < self.length_limit:\n","                        final_sentences.append(sentence)\n","                        current_len += sentence_len\n","                    else:\n","                        sentence = sentence[: self.length_limit - current_len]\n","                        final_sentences.append(sentence)\n","                        break\n","            sentences = final_sentences\n","\n","        final_sentences = []\n","        for sentence in sentences:\n","            sentence = Rouge.REMOVE_CHAR_PATTERN.sub(\" \", sentence.lower()).strip()\n","\n","            tokens = self.tokenize_text(Rouge.REMOVE_CHAR_PATTERN.sub(\" \", sentence))\n","\n","            sentence = \" \".join(tokens)\n","\n","            final_sentences.append(sentence)\n","\n","        return final_sentences"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["'''\n","rouge score 계산을 위해 필요한 함수입니다.\n","데이터셋에 따라 compute rouge 함수를 조금씩 수정해주어야합니다.\n","아래의 코드는 설명을 진행합니다.\n","'''\n","import os\n","from glob import glob\n","from tqdm import tqdm\n","\n","class RougeScorer:\n","    def __init__(self):\n","\n","        self.rouge_evaluator = Rouge(\n","            metrics=[\"rouge-n\", \"rouge-l\"],\n","            max_n=2,\n","            limit_length=True,\n","            length_limit=1000,\n","            length_limit_type=\"words\",\n","            apply_avg=True,\n","            apply_best=False,\n","            alpha=0.5,  # Default F1_score\n","            weight_factor=1.2,\n","        )\n","\n","    def compute_rouge(self, ref_list, hyp_list):\n","        '''\n","        ref_path : 정답 문장\n","        hyp_path : 예측 문장\n","        '''\n","\n","        print(\"-\" * 50)\n","        print(\"# of Testset :\", len(hyp_list))\n","        print(\"-\" * 50)\n","\n","        self.reference_summaries = []\n","        self.generated_summaries = []\n","\n","        for ref_doc, hyp_doc in tqdm(zip(ref_list, hyp_list), total=len(ref_list)):\n","\n","            ref_doc = \" \".join(ref_doc)\n","            hyp_doc = \" \".join(hyp_doc)\n","\n","            self.reference_summaries.append(ref_doc)\n","            self.generated_summaries.append(hyp_doc)\n","\n","        scores = self.rouge_evaluator.get_scores(self.generated_summaries, self.reference_summaries) # score를 계산하는 함수\n","\n","        str_scores = self.format_rouge_scores(scores)\n","        print(str_scores)\n","        self.save_rouge_scores(str_scores)\n","        return str_scores\n","\n","    def save_rouge_scores(self, str_scores):\n","        with open(\"rouge_scores.txt\", \"w\") as output:\n","            output.write(str_scores)\n","\n","    def format_rouge_scores(self, scores):\n","        return \"\"\"\\n\n","    ****** ROUGE SCORES ******\n","    ** ROUGE 1\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\n","    ** ROUGE 2\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\n","    ** ROUGE L\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\"\"\".format(\n","            scores[\"rouge-1\"][\"f\"],\n","            scores[\"rouge-1\"][\"p\"],\n","            scores[\"rouge-1\"][\"r\"],\n","            scores[\"rouge-2\"][\"f\"],\n","            scores[\"rouge-2\"][\"p\"],\n","            scores[\"rouge-2\"][\"r\"],\n","            scores[\"rouge-l\"][\"f\"],\n","            scores[\"rouge-l\"][\"p\"],\n","            scores[\"rouge-l\"][\"r\"],\n","        )"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","# of Testset : 1217\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1217/1217 [00:00<00:00, 240708.67it/s]\n"]}],"source":["rouge_eval = RougeScorer()\n","result = rouge_eval.compute_rouge(all_label, all_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UYerzcHaKWr"},"outputs":[],"source":["# SummarRunner의 성능은 아래와 같이 도출됩니다.\n","# 참고 : TextRank보다 높음\n","\n","# ****** ROUGE SCORES ******\n","# ** ROUGE 1\n","# F1        >> 0.519\n","# Precision >> 0.576\n","# Recall    >> 0.498\n","# ** ROUGE 2\n","# F1        >> 0.384\n","# Precision >> 0.421\n","# Recall    >> 0.370\n","# ** ROUGE L\n","# F1        >> 0.424\n","# Precision >> 0.470\n","# Recall    >> 0.407"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"자연어처리_4_문서요약_TextRank.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
