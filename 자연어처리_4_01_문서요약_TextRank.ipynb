{"cells":[{"cell_type":"markdown","metadata":{"id":"RDdaXxTuZ-oa"},"source":["## [LG 전자] 자연어 처리 # 4 : 문서요약 - (1)\n","\n","* TextRank를 이용한 추출 요약\n","* 예상 난이도 ⭐️⭐️"]},{"cell_type":"markdown","metadata":{"id":"5S57xUrStZHq"},"source":["## 강의 복습\n","\n","강의자료 : 자연어처리 4, AGENDA 02 - 그래프 기반의 추출요약"]},{"cell_type":"markdown","metadata":{"id":"pH2OUSs8tdg9"},"source":["## 실습 요약"]},{"cell_type":"markdown","metadata":{"id":"oZtcUJkERwfC"},"source":["1. 본 실습에서는 TextRank를 활용하여 추출요약 모델을 구축합니다.\n","2. TextRank는 별도의 학습 과정을 진행하지 않는 비지도학습 기반의 모델입니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XvnpBm1PtVeV"},"source":["------"]},{"cell_type":"markdown","metadata":{"id":"xVvGtj7vYQ5v"},"source":["### STEP 0. 환경 구축하기\n","* 필요한 library들을 import 합니다"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YBWSfQGI-a8F"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install gensim==3.8.3"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1643076242178,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"WtIPKkNiaosp","outputId":"378a0a17-6bc1-4a22-b529-c0fc07977413"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python version:[3.8.0 (default, Nov  6 2019, 15:49:01) \n","[Clang 4.0.1 (tags/RELEASE_401/final)]].\n","PyTorch version:[1.9.0].\n","device:[cpu].\n"]}],"source":["import sys\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","plt.rcParams['axes.unicode_minus'] = False\n","#%matplotlib inline #생성한 figure를 notebook에서 볼 수있게 해주는 코드\n","\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","#check torch version & device\n","print (\"Python version:[%s].\"%(sys.version))\n","print (\"PyTorch version:[%s].\"%(torch.__version__))\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print (\"device:[%s].\"%(device)) # device에 cuda:0가 프린트 된다면 GPU를 사용하는 상태입니다"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# konlpy, Mecab 형태소 분석기 설치 스크립트 실행\n","!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rUM2BsZMcCzC"},"outputs":[],"source":["# set random seed \n","\n","def set_seed(random_seed):\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)\n","    \n","random_seed = 42\n","set_seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"FACcqNcFcExO"},"source":["### STEP 1. 데이터 준비하기\n","금일 실습에서는 **AIHUB**에서 제공하는 **한글 뉴스기사 요약 데이터**를 활용합니다.\n","* 데이터셋 출처\n","  * https://aihub.or.kr/aidata/8054\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5-Vn2GBei2Vf"},"outputs":[],"source":["# github에서 데이터 불러오기\n","!git clone https://github.com/KU-DIC/LG_natural_language_processing_day23"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_prvLfHKcGqQ"},"outputs":[],"source":["# 데이터셋 읽기\n","with open('./LG_natural_language_processing_day23/data/sum_data.json','r',encoding='utf-8') as f:\n","  data = json.load(f)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":565,"status":"ok","timestamp":1643076254652,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"aeFWxr9bMOWh","outputId":"f8b89e58-cb99-407c-f0f4-de781632affd"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12000/12000 [00:00<00:00, 459381.26it/s]\n"]}],"source":["# 분석에 사용할 형태로 가공하기\n","label = [] # extractive\n","document = [] # text\n","\n","for cur_news in tqdm(data['documents']):\n","  # 리뷰 문장\n","  document.append(cur_news['text'])\n","  label.append(cur_news['extractive'])"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"BnaQBc06MmWn"},"outputs":[],"source":["# 데이터 프레임 형태로 변환하기\n","df = {\n","    \"label\" : label,\n","    \"document\" : document\n","}\n","df = pd.DataFrame(df)"]},{"cell_type":"markdown","metadata":{"id":"vW0B011dTyOo"},"source":["### STEP 2. 전처리 진행 (Preprocessing)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WIySBkPocmLD"},"outputs":[],"source":["news_sentences = df['document'].to_list()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Q7j4w1z-tRuy"},"outputs":[],"source":["import re\n","def preprocess(text):\n","  text = re.sub('[-=+,#/\\?:^$~@*\\\"※~▲△&%ㆍ·!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', text)\n","  text = re.sub('[ㅠㅎㅋ]','', text)\n","  return text"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1643076268603,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"4dUBQnv6tg1f","outputId":"7b936da1-8f14-4aa8-d867-ba15c3601eb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12199/12199 [00:00<00:00, 256394.36it/s]\n","100%|██████████| 12199/12199 [00:00<00:00, 26911.00it/s]\n"]}],"source":["fixed_document = []\n","for cur_sentences in tqdm(news_sentences):\n","  fix_sent = []\n","  for sent in cur_sentences:\n","    fix_sent.extend(sent)\n","  fixed_document.append(fix_sent)\n","\n","normalize_document = []\n","for cur_sentences in tqdm(fixed_document):\n","  norm_sent = []\n","  for sent in cur_sentences:\n","    sentence = preprocess(sent['sentence'])\n","    norm_sent.append(sentence)\n","  normalize_document.append(norm_sent)\n","\n","df['normalize_document'] = normalize_document"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["label_sentence = []\n","for id, cur_doc in enumerate(df['normalize_document']):\n","  sent = []\n","  for idx in df['label'].iloc[id]:\n","    sent.append(cur_doc[idx])\n","  label_sentence.append(sent)\n","\n","df['label_sentence'] = label_sentence"]},{"cell_type":"markdown","metadata":{"id":"zjw-KFL0k5A1"},"source":["### STEP 3. 토큰화 진행 (Tokenization)\n","\n","* 문서 요약 실습에서는 단순 띄어쓰기 단위로 토큰화를 진행합니다\n","* 이유 : 문서요약 데이터는 하나의 데이터당 굉장히 많은 문장을 가지므로, 토큰화 과정에만 약 30분의 시간이 소요됨"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384917,"status":"ok","timestamp":1643076656483,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"FJ55fpYTvT0h","outputId":"76419604-3fa3-4f44-adf6-2f9a11945d23"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12199/12199 [28:14<00:00,  7.20it/s]\n"]}],"source":["# Okt(Open Korea Text)\n","# from konlpy.tag import Okt  \n","# okt = Okt() \n","\n","# tokenized_document = []\n","# for cur_doc in tqdm(normalize_document):\n","#   tokenized_sentence = []\n","#   for cur_sent in cur_doc:\n","#     sent = okt.morphs(cur_sent)\n","#     tokenized_sentence.append(sent)\n","#   tokenized_document.append(tokenized_sentence)\n","\n","# df['tokenized_document'] = tokenized_document"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenized_document = []\n","for cur_doc in tqdm(normalize_document):\n","  tokenized_sentence = []\n","  for cur_sent in cur_doc:\n","    sent = cur_sent.split(' ')\n","    tokenized_sentence.append(sent)\n","  tokenized_document.append(tokenized_sentence)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"XhUniskUrysU"},"outputs":[],"source":["df['tokenized_document'] = tokenized_document"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1643076657058,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"_KM7W6EaOLCi","outputId":"f5c86a13-4fd7-48e6-c3fe-9d8cb8f192d2"},"outputs":[{"data":{"text/plain":["(10972, 1217)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, test_df = train_test_split(df, test_size =0.1, random_state= 42)\n","\n","drop_list = [train_df.iloc[i].name for i in[845, 3035, 3936, 5246, 5417, 8988, 9710]]\n","train_df = train_df.drop(drop_list)\n","\n","drop_list = [test_df.iloc[i].name for i in [408,583,1000]]\n","test_df = test_df.drop(drop_list)\n","len(train_df) , len(test_df)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10972/10972 [00:00<00:00, 861812.08it/s]\n"]}],"source":["aggregate_document =[]\n","for cur_doc in tqdm(train_df['tokenized_document']):\n","    _aggregate_document = [i for i in cur_doc]\n","    aggregate_document.append(_aggregate_document[0])\n","\n","train_df['aggregate_document'] = aggregate_document"]},{"cell_type":"markdown","metadata":{"id":"NhZtdagGsTVe"},"source":["### STEP 4. 벡터화 진행 (Vectorization)\n","* 해당 실습에서는 가장 성능이 좋았던 FastText를 활용하여 벡터화를 수행함\n","* 사전학습 모델 설명\n","* 실습에서 사용하지 않는 이유\n","  * 다운로드, 용량 (4GB)\n","  "]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43614,"status":"ok","timestamp":1643076700664,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"QJjqfAyOrgKn","outputId":"d4cd374a-a74b-4569-e15d-0a450a02e2cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 9.29 s, sys: 629 ms, total: 9.92 s\n","Wall time: 7.88 s\n"]}],"source":["%%time\n","from gensim.models import FastText\n","\n","model = FastText(\n","    sentences = aggregate_document,\n","    size=100,\n","    window=5,\n","    min_count=1,\n","    workers=4)"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"Cb-lxhdkqq_g"},"outputs":[],"source":["# vocab"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"4bUMcLxWW8a_"},"outputs":[],"source":["vocab = list(model.wv.vocab)\n","train_sentence = train_df['tokenized_document'].to_list()\n","test_sentence = test_df['tokenized_document'].to_list()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"p3Z9Zej2lJu3"},"outputs":[],"source":["word2index = {'<PAD>':0, '<UNK>':1}\n","\n","for v in vocab: # v는 vocab 객체 하나를 의미함\n","  if word2index.get(v) is None:\n","    word2index[v] = len(word2index) # 단어별 index 부여\n","\n","index2word = {}\n","for idx, vo in word2index.items():\n","  index2word[vo] = idx\n","\n","# 한줄로 구현하기\n","# index2word = {v:idx for idx, v in word2index.items()}"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"RSCapb6Cy_rc"},"outputs":[],"source":["fasttext_vector = []\n","for key in word2index.keys():\n","  if key in '<PAD>' or '<UNK>': # 두가지 단어는 vocab에 속하지 않음 \n","    fasttext_vector.append(np.random.randn(100,)) # random한 값으로 초기화 하여 제공\n","  else:\n","    fasttext_vector.append(model.wv[key])\n","  \n","fasttext_matrix = np.vstack(fasttext_vector)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1643076782171,"user":{"displayName":"‍이유경[ 대학원석·박사통합과정재학 / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixRazgnIE9jgzx19kPym5cLsIPqoUxh5gz3ue5=s64","userId":"03303826414239054153"},"user_tz":-540},"id":"Xur5_ZgSoP8A","outputId":"268b4eaa-abf7-48b2-f0ef-fd70f2cfa944"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab 개수 :  22667\n","word matrix shape :  (22669, 100)\n"]}],"source":["print('vocab 개수 : ',len(vocab))\n","print('word matrix shape : ',fasttext_matrix.shape) # '<PAD>''<UNK>'를 추가해주었기 때문에 vocab보다 2개 많은 상태"]},{"cell_type":"markdown","metadata":{"id":"6v2UDIcOEoKb"},"source":["### STEP 5. 모델 구축하기 (Modeling)\n","* TextRank를 활용하여 문서 요약 모델 구축하기\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"4tsH9OOEYc-t"},"outputs":[],"source":["import re\n","import itertools\n","import networkx as nx\n","import numpy as np\n","from numpy import dot\n","from numpy.linalg import norm\n","\n","class TextRank:\n","    def __init__(self, df, word2index, word_embedding, min_sim, top_k):\n","        self.df = df\n","        self.word2index = word2index\n","        self.word_embedding = word_embedding\n","        self.min_sim = min_sim\n","        self.top_k = top_k\n","\n","    \n","    def make_sentence_graph(self, sentence):\n","        '''\n","        sentence graph를 생성하는 함수\n","        '''\n","        sentence_graph = nx.Graph()  # initialize an undirected graph\n","        sentence_graph.add_nodes_from(sentence)\n","\n","        nodePairs = list(itertools.combinations(sentence, 2))\n","\n","        # add edges to the graph (weighted by Levenshtein distance)\n","        for pair in nodePairs:\n","            node1 = pair[0]\n","            node2 = pair[1]\n","\n","            cos_sim = dot(sentence[pair[0]][1], sentence[pair[1]][1]) / (\n","                norm(sentence[pair[0]][1]) * norm(sentence[pair[1]][1])\n","            )\n","            if cos_sim > self.min_sim: # 각 노드 pair간 유사도가 최소 유사도를 넘는 경우 graph에 추가함\n","                sentence_graph.add_edge(node1, node2, weight=cos_sim)\n","\n","        return sentence_graph\n","\n","    def extract_sentence(self, sentence_graph, sentence):\n","        '''\n","        하나의 document에서 중요한 sentence를 추출하는 함수\n","        '''\n","        calculated_page_rank = nx.pagerank(\n","            sentence_graph, alpha=0.85, max_iter=100, weight=\"weight\"\n","        )\n","\n","        sentences = sorted(calculated_page_rank, key=calculated_page_rank.get, reverse=True)\n","\n","        modified_sentence = sentences[: -len(sentences) + self.top_k]\n","        result_sentence = [(sentence[sent][0], sent) for sent in modified_sentence]\n","\n","        return result_sentence\n","\n","\n","    def sentence_summary(self):\n","        \"\"\"\n","        sentence 요약을 진행하는 main 함수 \n","        \"\"\"\n","        sentence_sum_result = []\n","        for doc_idx , (cur_data, cur_doc)  in enumerate(tqdm(zip(self.df['tokenized_document'], self.df['normalize_document']))):\n","            # cur_data == one article\n","            sentence = {}\n","            # article 자체로 그래프 생성해야함 - 문장단\n","            for idx, (tokenized_sent, sent) in enumerate(zip(cur_data, cur_doc)):\n","                sentence_vector = []\n","                for tok in tokenized_sent:\n","                    try:\n","                        sentence_vector.append(self.word_embedding[word2index[tok]])\n","                    except:\n","                        sentence_vector.append(self.word_embedding[word2index['<UNK>']])\n","                sentence[sent] = [idx, np.mean(sentence_vector, axis=0)]\n","                sentence_graph = self.make_sentence_graph(sentence)\n","\n","            extracted_sentence = self.extract_sentence(sentence_graph, sentence)\n","            sentence_sum_result.append(extracted_sentence)\n","\n","        return sentence_sum_result"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["MIN_SIM = 0.5\n","TOP_K = 3\n","\n","model = TextRank(\n","    df=test_df, # 학습을 필요로 하지 않는 비지도 학습 방법론이므로, 다른 방법론과의 비교를 위해 test_df로 진행\n","    word2index=word2index, \n","    word_embedding=fasttext_matrix, \n","    min_sim=MIN_SIM, \n","    top_k=TOP_K)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["1217it [00:09, 127.98it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 9.52 s, sys: 32 ms, total: 9.55 s\n","Wall time: 9.51 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","# [time] train_df : 1m24s / test_df :9s\n","output = model.sentence_summary()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["all_pred = []\n","for cur_output in output:\n","    pred = []\n","    for index, sentence in cur_output:\n","        pred.append(sentence)\n","    # pred.sort() # index에서만\n","    all_pred.append(pred)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1217 1217\n"]}],"source":["all_label = test_df['label_sentence'].to_list()\n","print(len(all_label),len(all_pred))"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["'''\n","rouge score 계산을 위한 코드이며, \n","해당 실습에서는 score 계산에 필요한 전체적인 흐름을 따라갈 목적으로서 해당 코드를 사용합니다.\n","즉, rouge score의 계산원리를 모두 익히지 않아도 됩니다.\n","'''\n","\n","import os\n","import re\n","import platform\n","import itertools\n","import collections\n","import pkg_resources  # pip install py-rouge\n","from io import open\n","\n","if platform.system() == \"Windows\":\n","    try:\n","        from konlpy.tag import Mecab\n","        # from eunjeon import Mecab\n","    except:\n","        print(\"please install eunjeon module\")\n","else:  # Ubuntu일 경우\n","    from konlpy.tag import Mecab\n","\n","\n","class Rouge:\n","    DEFAULT_METRICS = {\"rouge-n\"}\n","    DEFAULT_N = 1\n","    STATS = [\"f\", \"p\", \"r\"]\n","    AVAILABLE_METRICS = {\"rouge-n\", \"rouge-l\", \"rouge-w\"}\n","    AVAILABLE_LENGTH_LIMIT_TYPES = {\"words\", \"bytes\"}\n","    REMOVE_CHAR_PATTERN = re.compile(\"[^A-Za-z0-9가-힣]\")\n","\n","    def __init__(\n","        self,\n","        metrics=None,\n","        max_n=None,\n","        limit_length=True,\n","        length_limit=1000,\n","        length_limit_type=\"words\",\n","        apply_avg=True,\n","        apply_best=False,\n","        use_tokenizer=True,\n","        alpha=0.5,\n","        weight_factor=1.0,\n","    ):\n","        self.metrics = metrics[:] if metrics is not None else Rouge.DEFAULT_METRICS\n","        for m in self.metrics:\n","            if m not in Rouge.AVAILABLE_METRICS:\n","                raise ValueError(\"Unknown metric '{}'\".format(m))\n","\n","        self.max_n = max_n if \"rouge-n\" in self.metrics else None\n","        # Add all rouge-n metrics\n","        if self.max_n is not None:\n","            index_rouge_n = self.metrics.index(\"rouge-n\")\n","            del self.metrics[index_rouge_n]\n","            self.metrics += [\"rouge-{}\".format(n) for n in range(1, self.max_n + 1)]\n","        self.metrics = set(self.metrics)\n","\n","        self.limit_length = limit_length\n","        if self.limit_length:\n","            if length_limit_type not in Rouge.AVAILABLE_LENGTH_LIMIT_TYPES:\n","                raise ValueError(\"Unknown length_limit_type '{}'\".format(length_limit_type))\n","\n","        self.length_limit = length_limit\n","        if self.length_limit == 0:\n","            self.limit_length = False\n","        self.length_limit_type = length_limit_type\n","\n","        self.use_tokenizer = use_tokenizer\n","        if use_tokenizer:\n","            self.tokenizer = Mecab()\n","\n","        self.apply_avg = apply_avg\n","        self.apply_best = apply_best\n","        self.alpha = alpha\n","        self.weight_factor = weight_factor\n","        if self.weight_factor <= 0:\n","            raise ValueError(\"ROUGE-W weight factor must greater than 0.\")\n","\n","    def tokenize_text(self, text):\n","        return self.tokenizer.morphs(text)\n","\n","    @staticmethod\n","    def split_into_sentences(text):\n","        return text.split(\"\\n\")\n","\n","    @staticmethod\n","    def _get_ngrams(n, text):\n","        ngram_set = collections.defaultdict(int)\n","        max_index_ngram_start = len(text) - n\n","        for i in range(max_index_ngram_start + 1):\n","            ngram_set[tuple(text[i : i + n])] += 1\n","        return ngram_set\n","\n","    @staticmethod\n","    def _split_into_words(sentences):\n","        return list(itertools.chain(*[_.split() for _ in sentences]))\n","\n","    @staticmethod\n","    def _get_word_ngrams_and_length(n, sentences):\n","        assert len(sentences) > 0\n","        assert n > 0\n","\n","        tokens = Rouge._split_into_words(sentences)\n","        return Rouge._get_ngrams(n, tokens), tokens, len(tokens) - (n - 1)\n","\n","    @staticmethod\n","    def _get_unigrams(sentences):\n","        assert len(sentences) > 0\n","\n","        tokens = Rouge._split_into_words(sentences)\n","        unigram_set = collections.defaultdict(int)\n","        for token in tokens:\n","            unigram_set[token] += 1\n","        return unigram_set, len(tokens)\n","\n","    @staticmethod\n","    def _compute_p_r_f_score(\n","        evaluated_count,\n","        reference_count,\n","        overlapping_count,\n","        alpha=0.5,\n","        weight_factor=1.0,\n","    ):\n","        precision = 0.0 if evaluated_count == 0 else overlapping_count / float(evaluated_count)\n","        if weight_factor != 1.0:\n","            precision = precision ** (1.0 / weight_factor)\n","        recall = 0.0 if reference_count == 0 else overlapping_count / float(reference_count)\n","        if weight_factor != 1.0:\n","            recall = recall ** (1.0 / weight_factor)\n","        f1_score = Rouge._compute_f_score(precision, recall, alpha)\n","        return {\"f\": f1_score, \"p\": precision, \"r\": recall}\n","\n","    @staticmethod\n","    def _compute_f_score(precision, recall, alpha=0.5):\n","        return (\n","            0.0\n","            if (recall == 0.0 or precision == 0.0)\n","            else precision * recall / ((1 - alpha) * precision + alpha * recall)\n","        )\n","\n","    @staticmethod\n","    def _compute_ngrams(evaluated_sentences, reference_sentences, n):\n","        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n","            raise ValueError(\"Collections must contain at least 1 sentence.\")\n","\n","        evaluated_ngrams, _, evaluated_count = Rouge._get_word_ngrams_and_length(\n","            n, evaluated_sentences\n","        )\n","        reference_ngrams, _, reference_count = Rouge._get_word_ngrams_and_length(\n","            n, reference_sentences\n","        )\n","\n","        # Gets the overlapping ngrams between evaluated and reference\n","        overlapping_ngrams = set(evaluated_ngrams.keys()).intersection(set(reference_ngrams.keys()))\n","        overlapping_count = 0\n","        for ngram in overlapping_ngrams:\n","            overlapping_count += min(evaluated_ngrams[ngram], reference_ngrams[ngram])\n","\n","        return evaluated_count, reference_count, overlapping_count\n","\n","    @staticmethod\n","    def _compute_ngrams_lcs(evaluated_sentences, reference_sentences, weight_factor=1.0):\n","        def _lcs(x, y):\n","            m = len(x)\n","            n = len(y)\n","            vals = collections.defaultdict(int)\n","            dirs = collections.defaultdict(int)\n","\n","            for i in range(1, m + 1):\n","                for j in range(1, n + 1):\n","                    if x[i - 1] == y[j - 1]:\n","                        vals[i, j] = vals[i - 1, j - 1] + 1\n","                        dirs[i, j] = \"|\"\n","                    elif vals[i - 1, j] >= vals[i, j - 1]:\n","                        vals[i, j] = vals[i - 1, j]\n","                        dirs[i, j] = \"^\"\n","                    else:\n","                        vals[i, j] = vals[i, j - 1]\n","                        dirs[i, j] = \"<\"\n","\n","            return vals, dirs\n","\n","        def _wlcs(x, y, weight_factor):\n","            m = len(x)\n","            n = len(y)\n","            vals = collections.defaultdict(float)\n","            dirs = collections.defaultdict(int)\n","            lengths = collections.defaultdict(int)\n","\n","            for i in range(1, m + 1):\n","                for j in range(1, n + 1):\n","                    if x[i - 1] == y[j - 1]:\n","                        length_tmp = lengths[i - 1, j - 1]\n","                        vals[i, j] = (\n","                            vals[i - 1, j - 1]\n","                            + (length_tmp + 1) ** weight_factor\n","                            - length_tmp ** weight_factor\n","                        )\n","                        dirs[i, j] = \"|\"\n","                        lengths[i, j] = length_tmp + 1\n","                    elif vals[i - 1, j] >= vals[i, j - 1]:\n","                        vals[i, j] = vals[i - 1, j]\n","                        dirs[i, j] = \"^\"\n","                        lengths[i, j] = 0\n","                    else:\n","                        vals[i, j] = vals[i, j - 1]\n","                        dirs[i, j] = \"<\"\n","                        lengths[i, j] = 0\n","\n","            return vals, dirs\n","\n","        def _mark_lcs(mask, dirs, m, n):\n","            while m != 0 and n != 0:\n","                if dirs[m, n] == \"|\":\n","                    m -= 1\n","                    n -= 1\n","                    mask[m] = 1\n","                elif dirs[m, n] == \"^\":\n","                    m -= 1\n","                elif dirs[m, n] == \"<\":\n","                    n -= 1\n","                else:\n","                    raise UnboundLocalError(\"Illegal move\")\n","\n","            return mask\n","\n","        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n","            raise ValueError(\"Collections must contain at least 1 sentence.\")\n","\n","        evaluated_unigrams_dict, evaluated_count = Rouge._get_unigrams(evaluated_sentences)\n","        reference_unigrams_dict, reference_count = Rouge._get_unigrams(reference_sentences)\n","\n","        # Has to use weight factor for WLCS\n","        use_WLCS = weight_factor != 1.0\n","        if use_WLCS:\n","            evaluated_count = evaluated_count ** weight_factor\n","            reference_count = 0\n","\n","        overlapping_count = 0.0\n","        for reference_sentence in reference_sentences:\n","            reference_sentence_tokens = reference_sentence.split()\n","            if use_WLCS:\n","                reference_count += len(reference_sentence_tokens) ** weight_factor\n","            hit_mask = [0 for _ in range(len(reference_sentence_tokens))]\n","\n","            for evaluated_sentence in evaluated_sentences:\n","                evaluated_sentence_tokens = evaluated_sentence.split()\n","\n","                if use_WLCS:\n","                    _, lcs_dirs = _wlcs(\n","                        reference_sentence_tokens,\n","                        evaluated_sentence_tokens,\n","                        weight_factor,\n","                    )\n","                else:\n","                    _, lcs_dirs = _lcs(reference_sentence_tokens, evaluated_sentence_tokens)\n","                _mark_lcs(\n","                    hit_mask,\n","                    lcs_dirs,\n","                    len(reference_sentence_tokens),\n","                    len(evaluated_sentence_tokens),\n","                )\n","\n","            overlapping_count_length = 0\n","            for ref_token_id, val in enumerate(hit_mask):\n","                if val == 1:\n","                    token = reference_sentence_tokens[ref_token_id]\n","                    if evaluated_unigrams_dict[token] > 0 and reference_unigrams_dict[token] > 0:\n","                        evaluated_unigrams_dict[token] -= 1\n","                        reference_unigrams_dict[ref_token_id] -= 1\n","\n","                        if use_WLCS:\n","                            overlapping_count_length += 1\n","                            if (\n","                                ref_token_id + 1 < len(hit_mask) and hit_mask[ref_token_id + 1] == 0\n","                            ) or ref_token_id + 1 == len(hit_mask):\n","                                overlapping_count += overlapping_count_length ** weight_factor\n","                                overlapping_count_length = 0\n","                        else:\n","                            overlapping_count += 1\n","\n","        if use_WLCS:\n","            reference_count = reference_count ** weight_factor\n","\n","        return evaluated_count, reference_count, overlapping_count\n","\n","    def get_scores(self, hypothesis, references):\n","        if isinstance(hypothesis, str):\n","            hypothesis, references = [hypothesis], [references]\n","\n","        if type(hypothesis) != type(references):\n","            raise ValueError(\"'hyps' and 'refs' are not of the same type\")\n","\n","        if len(hypothesis) != len(references):\n","            raise ValueError(\"'hyps' and 'refs' do not have the same length\")\n","        scores = {}\n","        has_rouge_n_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].isdigit()]) > 0\n","        )\n","        if has_rouge_n_metric:\n","            scores.update(self._get_scores_rouge_n(hypothesis, references))\n","            # scores = {**scores, **self._get_scores_rouge_n(hypothesis, references)}\n","\n","        has_rouge_l_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].lower() == \"l\"]) > 0\n","        )\n","        if has_rouge_l_metric:\n","            scores.update(self._get_scores_rouge_l_or_w(hypothesis, references, False))\n","            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, False)}\n","\n","        has_rouge_w_metric = (\n","            len([metric for metric in self.metrics if metric.split(\"-\")[-1].lower() == \"w\"]) > 0\n","        )\n","        if has_rouge_w_metric:\n","            scores.update(self._get_scores_rouge_l_or_w(hypothesis, references, True))\n","            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, True)}\n","\n","        return scores\n","\n","    def _get_scores_rouge_n(self, all_hypothesis, all_references):\n","        metrics = [metric for metric in self.metrics if metric.split(\"-\")[-1].isdigit()]\n","\n","        if self.apply_avg or self.apply_best:\n","            scores = {metric: {stat: 0.0 for stat in Rouge.STATS} for metric in metrics}\n","        else:\n","            scores = {\n","                metric: [{stat: [] for stat in Rouge.STATS} for _ in range(len(all_hypothesis))]\n","                for metric in metrics\n","            }\n","\n","        for sample_id, (hypothesis, references) in enumerate(zip(all_hypothesis, all_references)):\n","            assert isinstance(hypothesis, str)\n","            has_multiple_references = False\n","            if isinstance(references, list):\n","                has_multiple_references = len(references) > 1\n","                if not has_multiple_references:\n","                    references = references[0]\n","\n","            # Prepare hypothesis and reference(s)\n","            hypothesis = self._preprocess_summary_as_a_whole(hypothesis)\n","            references = (\n","                [self._preprocess_summary_as_a_whole(reference) for reference in references]\n","                if has_multiple_references\n","                else [self._preprocess_summary_as_a_whole(references)]\n","            )\n","\n","            # Compute scores\n","            for metric in metrics:\n","                suffix = metric.split(\"-\")[-1]\n","                n = int(suffix)\n","\n","                # Aggregate\n","                if self.apply_avg:\n","                    # average model\n","                    total_hypothesis_ngrams_count = 0\n","                    total_reference_ngrams_count = 0\n","                    total_ngrams_overlapping_count = 0\n","\n","                    for reference in references:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                        total_hypothesis_ngrams_count += hypothesis_count\n","                        total_reference_ngrams_count += reference_count\n","                        total_ngrams_overlapping_count += overlapping_ngrams\n","\n","                    score = Rouge._compute_p_r_f_score(\n","                        total_hypothesis_ngrams_count,\n","                        total_reference_ngrams_count,\n","                        total_ngrams_overlapping_count,\n","                        self.alpha,\n","                    )\n","\n","                    for stat in Rouge.STATS:\n","                        scores[metric][stat] += score[stat]\n","                else:\n","                    # Best model\n","                    if self.apply_best:\n","                        best_current_score = None\n","                        for reference in references:\n","                            (\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                            score = Rouge._compute_p_r_f_score(\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                                self.alpha,\n","                            )\n","                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n","                                best_current_score = score\n","\n","                        for stat in Rouge.STATS:\n","                            scores[metric][stat] += best_current_score[stat]\n","                    # Keep all\n","                    else:\n","                        for reference in references:\n","                            (\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n","                            score = Rouge._compute_p_r_f_score(\n","                                hypothesis_count,\n","                                reference_count,\n","                                overlapping_ngrams,\n","                                self.alpha,\n","                            )\n","                            for stat in Rouge.STATS:\n","                                scores[metric][sample_id][stat].append(score[stat])\n","\n","        # Compute final score with the average or the the max\n","        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n","            for metric in metrics:\n","                for stat in Rouge.STATS:\n","                    scores[metric][stat] /= len(all_hypothesis)\n","\n","        return scores\n","\n","    def _get_scores_rouge_l_or_w(self, all_hypothesis, all_references, use_w=False):\n","        metric = \"rouge-w\" if use_w else \"rouge-l\"\n","        if self.apply_avg or self.apply_best:\n","            scores = {metric: {stat: 0.0 for stat in Rouge.STATS}}\n","        else:\n","            scores = {\n","                metric: [{stat: [] for stat in Rouge.STATS} for _ in range(len(all_hypothesis))]\n","            }\n","\n","        for sample_id, (hypothesis_sentences, references_sentences) in enumerate(\n","            zip(all_hypothesis, all_references)\n","        ):\n","            assert isinstance(hypothesis_sentences, str)\n","            has_multiple_references = False\n","            if isinstance(references_sentences, list):\n","                has_multiple_references = len(references_sentences) > 1\n","                if not has_multiple_references:\n","                    references_sentences = references_sentences[0]\n","\n","            # Prepare hypothesis and reference(s)\n","            hypothesis_sentences = self._preprocess_summary_per_sentence(hypothesis_sentences)\n","            references_sentences = (\n","                [\n","                    self._preprocess_summary_per_sentence(reference)\n","                    for reference in references_sentences\n","                ]\n","                if has_multiple_references\n","                else [self._preprocess_summary_per_sentence(references_sentences)]\n","            )\n","\n","            # Compute scores\n","            # Aggregate\n","            if self.apply_avg:\n","                # average model\n","                total_hypothesis_ngrams_count = 0\n","                total_reference_ngrams_count = 0\n","                total_ngrams_overlapping_count = 0\n","\n","                for reference_sentences in references_sentences:\n","                    (\n","                        hypothesis_count,\n","                        reference_count,\n","                        overlapping_ngrams,\n","                    ) = Rouge._compute_ngrams_lcs(\n","                        hypothesis_sentences,\n","                        reference_sentences,\n","                        self.weight_factor if use_w else 1.0,\n","                    )\n","                    total_hypothesis_ngrams_count += hypothesis_count\n","                    total_reference_ngrams_count += reference_count\n","                    total_ngrams_overlapping_count += overlapping_ngrams\n","\n","                score = Rouge._compute_p_r_f_score(\n","                    total_hypothesis_ngrams_count,\n","                    total_reference_ngrams_count,\n","                    total_ngrams_overlapping_count,\n","                    self.alpha,\n","                    self.weight_factor if use_w else 1.0,\n","                )\n","                for stat in Rouge.STATS:\n","                    scores[metric][stat] += score[stat]\n","            else:\n","                # Best model\n","                if self.apply_best:\n","                    best_current_score = None\n","                    best_current_score_wlcs = None\n","                    for reference_sentences in references_sentences:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams_lcs(\n","                            hypothesis_sentences,\n","                            reference_sentences,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","                        score = Rouge._compute_p_r_f_score(\n","                            total_hypothesis_ngrams_count,\n","                            total_reference_ngrams_count,\n","                            total_ngrams_overlapping_count,\n","                            self.alpha,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","\n","                        if use_w:\n","                            reference_count_for_score = reference_count ** (\n","                                1.0 / self.weight_factor\n","                            )\n","                            overlapping_ngrams_for_score = overlapping_ngrams\n","                            score_wlcs = (\n","                                overlapping_ngrams_for_score / reference_count_for_score\n","                            ) ** (1.0 / self.weight_factor)\n","\n","                            if (\n","                                best_current_score_wlcs is None\n","                                or score_wlcs > best_current_score_wlcs\n","                            ):\n","                                best_current_score = score\n","                                best_current_score_wlcs = score_wlcs\n","                        else:\n","                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n","                                best_current_score = score\n","\n","                    for stat in Rouge.STATS:\n","                        scores[metric][stat] += best_current_score[stat]\n","                # Keep all\n","                else:\n","                    for reference_sentences in references_sentences:\n","                        (\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                        ) = Rouge._compute_ngrams_lcs(\n","                            hypothesis_sentences,\n","                            reference_sentences,\n","                            self.weight_factor if use_w else 1.0,\n","                        )\n","                        score = Rouge._compute_p_r_f_score(\n","                            hypothesis_count,\n","                            reference_count,\n","                            overlapping_ngrams,\n","                            self.alpha,\n","                            self.weight_factor,\n","                        )\n","\n","                        for stat in Rouge.STATS:\n","                            scores[metric][sample_id][stat].append(score[stat])\n","\n","        # Compute final score with the average or the the max\n","        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n","            for stat in Rouge.STATS:\n","                scores[metric][stat] /= len(all_hypothesis)\n","\n","        return scores\n","\n","    def _preprocess_summary_as_a_whole(self, summary):\n","        sentences = Rouge.split_into_sentences(summary)\n","\n","        # Truncate\n","        if self.limit_length:\n","            # By words\n","            if self.length_limit_type == \"words\":\n","                summary = \" \".join(sentences)\n","                all_tokens = summary.split()  # Counting as in the perls script\n","                summary = \" \".join(all_tokens[: self.length_limit])\n","\n","            # By bytes\n","            elif self.length_limit_type == \"bytes\":\n","                summary = \"\"\n","                current_len = 0\n","                for sentence in sentences:\n","                    sentence = sentence.strip()\n","                    sentence_len = len(sentence)\n","\n","                    if current_len + sentence_len < self.length_limit:\n","                        if current_len != 0:\n","                            summary += \" \"\n","                        summary += sentence\n","                        current_len += sentence_len\n","                    else:\n","                        if current_len > 0:\n","                            summary += \" \"\n","                        summary += sentence[: self.length_limit - current_len]\n","                        break\n","        else:\n","            summary = \" \".join(sentences)\n","\n","        summary = Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary.lower()).strip()\n","\n","        tokens = self.tokenize_text(Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary))\n","        preprocessed_summary = [\" \".join(tokens)]\n","\n","        return preprocessed_summary\n","\n","    def _preprocess_summary_per_sentence(self, summary):\n","        sentences = Rouge.split_into_sentences(summary)\n","\n","        # Truncate\n","        if self.limit_length:\n","            final_sentences = []\n","            current_len = 0\n","            # By words\n","            if self.length_limit_type == \"words\":\n","                for sentence in sentences:\n","                    tokens = sentence.strip().split()\n","                    tokens_len = len(tokens)\n","                    if current_len + tokens_len < self.length_limit:\n","                        sentence = \" \".join(tokens)\n","                        final_sentences.append(sentence)\n","                        current_len += tokens_len\n","                    else:\n","                        sentence = \" \".join(tokens[: self.length_limit - current_len])\n","                        final_sentences.append(sentence)\n","                        break\n","            # By bytes\n","            elif self.length_limit_type == \"bytes\":\n","                for sentence in sentences:\n","                    sentence = sentence.strip()\n","                    sentence_len = len(sentence)\n","                    if current_len + sentence_len < self.length_limit:\n","                        final_sentences.append(sentence)\n","                        current_len += sentence_len\n","                    else:\n","                        sentence = sentence[: self.length_limit - current_len]\n","                        final_sentences.append(sentence)\n","                        break\n","            sentences = final_sentences\n","\n","        final_sentences = []\n","        for sentence in sentences:\n","            sentence = Rouge.REMOVE_CHAR_PATTERN.sub(\" \", sentence.lower()).strip()\n","\n","            tokens = self.tokenize_text(Rouge.REMOVE_CHAR_PATTERN.sub(\" \", sentence))\n","\n","            sentence = \" \".join(tokens)\n","\n","            final_sentences.append(sentence)\n","\n","        return final_sentences"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["'''\n","rouge score 계산을 위해 필요한 함수입니다.\n","데이터셋에 따라 compute rouge 함수를 조금씩 수정해주어야합니다.\n","아래의 코드는 설명을 진행합니다.\n","'''\n","import os\n","from glob import glob\n","from tqdm import tqdm\n","\n","class RougeScorer:\n","    def __init__(self):\n","\n","        self.rouge_evaluator = Rouge(\n","            metrics=[\"rouge-n\", \"rouge-l\"],\n","            max_n=2,\n","            limit_length=True,\n","            length_limit=1000,\n","            length_limit_type=\"words\",\n","            apply_avg=True,\n","            apply_best=False,\n","            alpha=0.5,  # Default F1_score\n","            weight_factor=1.2,\n","        )\n","\n","    def compute_rouge(self, ref_list, hyp_list):\n","        '''\n","        ref_path : 정답 문장\n","        hyp_path : 예측 문장\n","        '''\n","\n","        print(\"-\" * 50)\n","        print(\"# of Testset :\", len(hyp_list))\n","        print(\"-\" * 50)\n","\n","        self.reference_summaries = []\n","        self.generated_summaries = []\n","\n","        for ref_doc, hyp_doc in tqdm(zip(ref_list, hyp_list), total=len(ref_list)):\n","\n","            ref_doc = \" \".join(ref_doc)\n","            hyp_doc = \" \".join(hyp_doc)\n","\n","            self.reference_summaries.append(ref_doc)\n","            self.generated_summaries.append(hyp_doc)\n","\n","        scores = self.rouge_evaluator.get_scores(self.generated_summaries, self.reference_summaries) # score를 계산하는 함수\n","\n","        str_scores = self.format_rouge_scores(scores)\n","        print(str_scores)\n","        self.save_rouge_scores(str_scores)\n","        return str_scores\n","\n","    def save_rouge_scores(self, str_scores):\n","        with open(\"rouge_scores.txt\", \"w\") as output:\n","            output.write(str_scores)\n","\n","    def format_rouge_scores(self, scores):\n","        return \"\"\"\\n\n","    ****** ROUGE SCORES ******\n","    ** ROUGE 1\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\n","    ** ROUGE 2\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\n","    ** ROUGE L\n","    F1        >> {:.3f}\n","    Precision >> {:.3f}\n","    Recall    >> {:.3f}\"\"\".format(\n","            scores[\"rouge-1\"][\"f\"],\n","            scores[\"rouge-1\"][\"p\"],\n","            scores[\"rouge-1\"][\"r\"],\n","            scores[\"rouge-2\"][\"f\"],\n","            scores[\"rouge-2\"][\"p\"],\n","            scores[\"rouge-2\"][\"r\"],\n","            scores[\"rouge-l\"][\"f\"],\n","            scores[\"rouge-l\"][\"p\"],\n","            scores[\"rouge-l\"][\"r\"],\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rouge_eval = RougeScorer()\n","result = rouge_eval.compute_rouge(all_label, all_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UYerzcHaKWr"},"outputs":[],"source":["# TextRank의 성능은 아래와 같이 도출됩니다.\n","\n","# ****** ROUGE SCORES ******\n","# ** ROUGE 1\n","# F1        >> 0.449\n","# Precision >> 0.441\n","# Recall    >> 0.483\n","# ** ROUGE 2\n","# F1        >> 0.274\n","# Precision >> 0.267\n","# Recall    >> 0.293\n","# ** ROUGE L\n","# F1        >> 0.313\n","# Precision >> 0.308\n","# Recall    >> 0.334"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"자연어처리_4_문서요약_TextRank.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
